#!/usr/bin/env python3
"""
ğŸ”¥ ì´ˆì •ë°€ ì£¼ì‹ ë¶„ì„ê¸° v4 (Deep Stock Analyzer) - ë‚˜ìŠ¤ë‹¥ì˜ ì‹  ì—ë””ì…˜
Zero Borrow ê°ì§€ + Gemini AI ë¶„ì„ + ì„¹í„°ë³„ íŠ¹í™” ë¶„ì„!

v4 ìƒˆ ê¸°ëŠ¥:
- ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤ (ë°”ì´ì˜¤í…/AIÂ·Tech/ì—ë„ˆì§€/ì¼ë°˜)
- ë°”ì´ì˜¤í… ì´‰ë§¤ ë¶„ì„ (FDA Fast Track, ClinicalTrials.gov ì—°ë™)
- 8-K ì£¼ìš” ì´ë²¤íŠ¸ íŒŒì‹± (FDA ìŠ¹ì¸, ì„ìƒê²°ê³¼, ê³„ì•½ ë“±)
- êµ¬ê¸€ ë‰´ìŠ¤ ë°±ì—… + ìµœê·¼ 60ì¼ í•„í„°
- SPAC/Earnout ì¡°ê±´ ìë™ ì¶”ì¶œ

v3 ê¸°ëŠ¥:
- SPAC/Earnout ì¡°ê±´ ìë™ ì¶”ì¶œ (S-4, DEFM14A)
- ë½ì—… ê°€ê²© ì¶”ì¶œ ê°œì„  (ê°€ê²© ê¸°ë°˜ ë½ì—…)
- google.genai ìƒˆ SDK ë§ˆì´ê·¸ë ˆì´ì…˜

Usage:
    uv run python deep_analyzer.py BNAI
    uv run python deep_analyzer.py BNAI --no-ai   # AI ë¶„ì„ ìŠ¤í‚µ
    uv run python deep_analyzer.py GLSI --normal  # ì¼ë°˜ ë¶„ì„ ëª¨ë“œ
"""

import sys
import os
import json
import re
from datetime import datetime, timedelta
from typing import Optional
import yfinance as yf
import requests
from bs4 import BeautifulSoup
import psycopg2
import pandas as pd

# Gemini API (ìƒˆ SDK)
from google import genai

# ============================================================
# ì„¤ì •
# ============================================================

DB_CONFIG = {
    "host": "localhost",
    "database": "dailystock",
    "user": "dailystock",
    "password": "dailystock123",
    "port": 5432
}

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0"
}

# Gemini ì„¤ì • (ìƒˆ SDK) - í™˜ê²½ë³€ìˆ˜ì—ì„œë§Œ ë¡œë“œ!
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
gemini_client = genai.Client(api_key=GEMINI_API_KEY) if GEMINI_API_KEY else None


def get_db():
    try:
        return psycopg2.connect(**DB_CONFIG)
    except:
        return None


def fmt_num(n, prefix="", suffix=""):
    """ìˆ«ì í¬ë§·íŒ…"""
    if n is None:
        return "N/A"
    if abs(n) >= 1e12:
        return f"{prefix}{n/1e12:.2f}T{suffix}"
    if abs(n) >= 1e9:
        return f"{prefix}{n/1e9:.2f}B{suffix}"
    if abs(n) >= 1e6:
        return f"{prefix}{n/1e6:.2f}M{suffix}"
    if abs(n) >= 1e3:
        return f"{prefix}{n/1e3:.1f}K{suffix}"
    return f"{prefix}{n:,.0f}{suffix}"


def fmt_pct(n, decimals=2):
    """í¼ì„¼íŠ¸ í¬ë§·íŒ…"""
    if n is None:
        return "N/A"
    return f"{n*100:.{decimals}f}%" if abs(n) < 1 else f"{n:.{decimals}f}%"


def section(title: str, emoji: str = "ğŸ“Š"):
    """ì„¹ì…˜ í—¤ë”"""
    print(f"\n{'='*70}")
    print(f"{emoji} {title}")
    print(f"{'='*70}")


def subsection(title: str):
    """ì„œë¸Œì„¹ì…˜"""
    print(f"\n{'â”€'*50}")
    print(f"  {title}")
    print(f"{'â”€'*50}")


# ============================================================
# 1. ê¸°ë³¸ ì •ë³´ (yfinance)
# ============================================================

def get_basic_info(ticker: str) -> dict:
    """yfinanceì—ì„œ ëª¨ë“  ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘"""
    stock = yf.Ticker(ticker)
    info = stock.info

    return {
        "info": info,
        "stock": stock,
        "name": info.get("shortName") or info.get("longName", ticker),
        "sector": info.get("sector"),
        "industry": info.get("industry"),
        "country": info.get("country"),
        "website": info.get("website"),
        "description": info.get("longBusinessSummary"),
        "employees": info.get("fullTimeEmployees"),
        "exchange": info.get("exchange"),
        "quote_type": info.get("quoteType"),
        # ê°€ê²©
        "price": info.get("currentPrice") or info.get("regularMarketPrice"),
        "prev_close": info.get("previousClose"),
        "open": info.get("open"),
        "day_high": info.get("dayHigh"),
        "day_low": info.get("dayLow"),
        "52w_high": info.get("fiftyTwoWeekHigh"),
        "52w_low": info.get("fiftyTwoWeekLow"),
        "50d_avg": info.get("fiftyDayAverage"),
        "200d_avg": info.get("twoHundredDayAverage"),
        "pre_market": info.get("preMarketPrice"),
        "post_market": info.get("postMarketPrice"),
        # ê±°ë˜ëŸ‰
        "volume": info.get("volume"),
        "avg_volume": info.get("averageVolume"),
        "avg_volume_10d": info.get("averageVolume10days"),
        # ì‹œì´/ì£¼ì‹ìˆ˜
        "market_cap": info.get("marketCap"),
        "enterprise_value": info.get("enterpriseValue"),
        "shares_outstanding": info.get("sharesOutstanding"),
        "float_shares": info.get("floatShares"),
        # ì¬ë¬´
        "revenue": info.get("totalRevenue"),
        "revenue_growth": info.get("revenueGrowth"),
        "ebitda": info.get("ebitda"),
        "net_income": info.get("netIncomeToCommon"),
        "eps": info.get("trailingEps"),
        "pe_ratio": info.get("trailingPE"),
        "total_cash": info.get("totalCash"),
        "total_debt": info.get("totalDebt"),
        "debt_to_equity": info.get("debtToEquity"),
        # ìˆ
        "short_ratio": info.get("shortRatio"),
        "short_pct_float": info.get("shortPercentOfFloat"),
        "shares_short": info.get("sharesShort"),
        "shares_short_prior": info.get("sharesShortPriorMonth"),
        "short_date": info.get("dateShortInterest"),
        # ë‚´ë¶€ì/ê¸°ê´€
        "insider_pct": info.get("heldPercentInsiders"),
        "institution_pct": info.get("heldPercentInstitutions"),
        # ê¸°íƒ€
        "beta": info.get("beta"),
        "target_mean": info.get("targetMeanPrice"),
        "recommendation": info.get("recommendationKey"),
    }


# ============================================================
# 2. Zero Borrow & Borrow Rate (shortablestocks.com)
# ============================================================

def get_borrow_data(ticker: str) -> dict:
    """shortablestocks.comì—ì„œ Zero Borrow ë° Borrow Rate ìˆ˜ì§‘"""
    url = f"https://www.shortablestocks.com/?{ticker}"

    try:
        resp = requests.get(url, headers=HEADERS, timeout=15)
        text = resp.text

        # Zero Borrow ê°ì§€ (ê°€ì¥ ì¤‘ìš”!)
        is_zero_borrow = "zero borrow" in text.lower()

        # Hard to Borrow ê°ì§€
        is_hard_to_borrow = "hard to borrow" in text.lower()

        # Short Interest ë°ì´í„° ì¶”ì¶œ (íŒ¨í„´: ë‚ ì§œ ìˆ«ì ìˆ«ì ìˆ«ì)
        si_match = re.search(r'(\d{1,2}/\d{1,2}/\d{4})\s+([\d,]+)\s+([\d,]+)\s+(\d+)', text)

        short_interest_shares = None
        avg_volume = None
        days_to_cover = None
        si_date = None

        if si_match:
            si_date = si_match.group(1)
            short_interest_shares = int(si_match.group(2).replace(',', ''))
            avg_volume = int(si_match.group(3).replace(',', ''))
            days_to_cover = int(si_match.group(4))

        # Borrow Rate ì¶”ì¶œ ì‹œë„ (í…Œì´ë¸”ì—ì„œ)
        borrow_rate = None
        available_shares = None

        # Fee Rate íŒ¨í„´ ì°¾ê¸°
        fee_match = re.search(r'(\d+\.?\d*)%?\s*fee', text.lower())
        if fee_match:
            borrow_rate = float(fee_match.group(1))

        # Available shares íŒ¨í„´
        avail_match = re.search(r'available[:\s]+([\d,]+)', text.lower())
        if avail_match:
            available_shares = int(avail_match.group(1).replace(',', ''))

        # Zero Borrowë©´ ê·¹ë‹¨ì  ì„¤ì •
        if is_zero_borrow:
            borrow_rate = 999.0  # ì‚¬ì‹¤ìƒ ë¬´í•œëŒ€
            available_shares = 0

        return {
            "is_zero_borrow": is_zero_borrow,
            "is_hard_to_borrow": is_hard_to_borrow,
            "borrow_rate": borrow_rate,
            "available_shares": available_shares,
            "short_interest_shares": short_interest_shares,
            "avg_volume": avg_volume,
            "days_to_cover": days_to_cover,
            "si_date": si_date,
            "source": "shortablestocks.com"
        }

    except Exception as e:
        print(f"  âš ï¸ Borrow ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return {
            "is_zero_borrow": None,
            "is_hard_to_borrow": None,
            "borrow_rate": None,
            "available_shares": None,
            "short_interest_shares": None,
            "avg_volume": None,
            "days_to_cover": None,
            "si_date": None,
            "source": None
        }


# ============================================================
# 3. Fintel ìŠ¤í€´ì¦ˆ ìŠ¤ì½”ì–´ (ì›¹ ìŠ¤í¬ë˜í•‘)
# ============================================================

def get_fintel_data(ticker: str) -> dict:
    """Fintelì—ì„œ ì¶”ê°€ ë°ì´í„° ì‹œë„"""
    url = f"https://fintel.io/ss/us/{ticker.lower()}"

    try:
        resp = requests.get(url, headers=HEADERS, timeout=10)
        text = resp.text

        # Short Squeeze Score ì°¾ê¸°
        score_match = re.search(r'short\s*squeeze\s*score[:\s]*(\d+\.?\d*)', text.lower())
        squeeze_score = float(score_match.group(1)) if score_match else None

        return {
            "fintel_squeeze_score": squeeze_score,
            "source": "fintel.io"
        }
    except:
        return {"fintel_squeeze_score": None, "source": None}


# ============================================================
# 3.5 SEC EDGAR í¬ì„/ë¹š/covenant ì •ë³´
# ============================================================

def get_sec_info(ticker: str) -> dict:
    """SEC EDGAR Full-Text Searchë¡œ ì›ŒëŸ°íŠ¸/í¬ì„/ë¹š/covenant ì •ë³´ ìˆ˜ì§‘"""

    sec_info = {
        "warrant_mentions": 0,
        "dilution_mentions": 0,
        "covenant_mentions": 0,
        "debt_mentions": 0,
        "lockup_mentions": 0,
        "offering_mentions": 0,  # S-3, 424B ë“±
        "positive_news": 0,
        "negative_news": 0,
        # í•´ì„
        "has_warrant_risk": False,
        "has_debt_covenant": False,
        "dilution_risk": False,
        "has_lockup": False,
        "has_offering_risk": False,
        "has_positive_news": False,
        "has_negative_news": False,
    }

    headers = {"User-Agent": "DailyStockStory/1.0 (contact@example.com)"}

    try:
        # í‚¤ì›Œë“œ ê²€ìƒ‰ (2024ë…„ ì´í›„)
        keywords = [
            ("warrant", "warrant_mentions"),
            ("dilution", "dilution_mentions"),
            ("covenant", "covenant_mentions"),
            ("debt", "debt_mentions"),
            ("lock-up OR lockup", "lockup_mentions"),
            ("S-3 OR 424B", "offering_mentions"),
        ]

        for keyword, field in keywords:
            search_url = f'https://efts.sec.gov/LATEST/search-index?q="{keyword}" AND "{ticker}"&dateRange=custom&startdt=2024-01-01'
            try:
                resp = requests.get(search_url, headers=headers, timeout=15)
                if resp.status_code == 200:
                    data = resp.json()
                    count = data.get("hits", {}).get("total", {}).get("value", 0)
                    sec_info[field] = count
            except:
                pass

        # í˜¸ì¬ í‚¤ì›Œë“œ (2025ë…„)
        positive_keywords = ["deal", "partnership", "contract", "agreement", "FDA approval"]
        for pk in positive_keywords:
            search_url = f'https://efts.sec.gov/LATEST/search-index?q="{pk}" AND "{ticker}"&dateRange=custom&startdt=2025-01-01'
            try:
                resp = requests.get(search_url, headers=headers, timeout=15)
                if resp.status_code == 200:
                    count = resp.json().get("hits", {}).get("total", {}).get("value", 0)
                    sec_info["positive_news"] += count
            except:
                pass

        # ì•…ì¬ í‚¤ì›Œë“œ (2025ë…„)
        negative_keywords = ["lawsuit", "bankruptcy", "default", "fraud", "investigation", "delisting"]
        for nk in negative_keywords:
            search_url = f'https://efts.sec.gov/LATEST/search-index?q="{nk}" AND "{ticker}"&dateRange=custom&startdt=2025-01-01'
            try:
                resp = requests.get(search_url, headers=headers, timeout=15)
                if resp.status_code == 200:
                    count = resp.json().get("hits", {}).get("total", {}).get("value", 0)
                    sec_info["negative_news"] += count
            except:
                pass

        # í•´ì„ (ì„ê³„ê°’)
        sec_info["has_warrant_risk"] = sec_info["warrant_mentions"] > 10
        sec_info["has_debt_covenant"] = sec_info["covenant_mentions"] > 3
        sec_info["dilution_risk"] = sec_info["dilution_mentions"] > 5
        sec_info["has_lockup"] = sec_info["lockup_mentions"] > 2
        sec_info["has_offering_risk"] = sec_info["offering_mentions"] > 3
        sec_info["has_positive_news"] = sec_info["positive_news"] > 50
        sec_info["has_negative_news"] = sec_info["negative_news"] > 20

    except Exception as e:
        print(f"    âš ï¸ SEC ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    return sec_info


# ============================================================
# 3.6 FTD (Failure to Deliver) ë°ì´í„° - SEC
# ============================================================

def get_ftd_data(ticker: str) -> dict:
    """SECì—ì„œ FTD ë°ì´í„° ìˆ˜ì§‘ (ìµœê·¼ 2ê°œì›”)"""
    ftd_info = {
        "total_ftd": 0,
        "recent_ftd": [],
        "avg_ftd": 0,
        "max_ftd": 0,
        "ftd_trend": "unknown",  # increasing, decreasing, stable
        "has_significant_ftd": False,
    }

    try:
        # SEC FTD íŒŒì¼ (ìµœê·¼ 2ê°œì›”)
        from datetime import datetime
        now = datetime.now()

        # SEC FTDëŠ” 2ì£¼ delayë¡œ ë°œí‘œë¨
        # ìµœê·¼ íŒŒì¼ 2ê°œ ì‹œë„
        months_to_check = []
        for i in range(3):
            check_date = now - timedelta(days=30 * i)
            months_to_check.append(check_date.strftime("%Y%m"))

        all_ftd = []

        for month in months_to_check[:2]:
            # ì²«ë²ˆì§¸ ë°˜ (1-15ì¼)
            url1 = f"https://www.sec.gov/files/data/fails-deliver-data/cnsfails{month}a.zip"
            # ë‘ë²ˆì§¸ ë°˜ (16-ë§ì¼)
            url2 = f"https://www.sec.gov/files/data/fails-deliver-data/cnsfails{month}b.zip"

            for url in [url1, url2]:
                try:
                    import io
                    import zipfile

                    resp = requests.get(url, headers={"User-Agent": "DailyStockStory/1.0"}, timeout=15)
                    if resp.status_code == 200:
                        with zipfile.ZipFile(io.BytesIO(resp.content)) as z:
                            for filename in z.namelist():
                                with z.open(filename) as f:
                                    content = f.read().decode('utf-8', errors='ignore')
                                    for line in content.split('\n'):
                                        if ticker.upper() in line.upper():
                                            parts = line.split('|')
                                            if len(parts) >= 5:
                                                try:
                                                    date = parts[0]
                                                    qty = int(parts[3]) if parts[3].isdigit() else 0
                                                    if qty > 0:
                                                        all_ftd.append({
                                                            "date": date,
                                                            "quantity": qty
                                                        })
                                                except:
                                                    pass
                except:
                    pass

        if all_ftd:
            # ì •ë ¬ (ìµœì‹ ìˆœ)
            all_ftd.sort(key=lambda x: x['date'], reverse=True)
            ftd_info["recent_ftd"] = all_ftd[:10]
            ftd_info["total_ftd"] = sum(f['quantity'] for f in all_ftd)
            ftd_info["avg_ftd"] = ftd_info["total_ftd"] // len(all_ftd) if all_ftd else 0
            ftd_info["max_ftd"] = max(f['quantity'] for f in all_ftd)

            # íŠ¸ë Œë“œ ë¶„ì„
            if len(all_ftd) >= 4:
                recent_avg = sum(f['quantity'] for f in all_ftd[:2]) / 2
                older_avg = sum(f['quantity'] for f in all_ftd[2:4]) / 2
                if recent_avg > older_avg * 1.5:
                    ftd_info["ftd_trend"] = "increasing ğŸ“ˆ"
                elif recent_avg < older_avg * 0.5:
                    ftd_info["ftd_trend"] = "decreasing ğŸ“‰"
                else:
                    ftd_info["ftd_trend"] = "stable"

            # ìœ ì˜ë¯¸í•œ FTDì¸ì§€ (10ë§Œì£¼ ì´ìƒ)
            ftd_info["has_significant_ftd"] = ftd_info["max_ftd"] > 100000

    except Exception as e:
        print(f"    âš ï¸ FTD ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    return ftd_info


# ============================================================
# 3.7 ì˜µì…˜ ì²´ì¸ ë¶„ì„
# ============================================================

def get_options_data(stock) -> dict:
    """ì˜µì…˜ ì²´ì¸ ë¶„ì„ (ê°ë§ˆ ìŠ¤í€´ì¦ˆ ê°€ëŠ¥ì„±)"""
    options_info = {
        "has_options": False,
        "nearest_expiry": None,
        "total_call_oi": 0,
        "total_put_oi": 0,
        "put_call_ratio": 0,
        "max_pain": 0,
        "gamma_exposure": [],
        "itm_calls": 0,  # In-the-money ì½œ
        "strikes_analysis": [],
    }

    try:
        # ì˜µì…˜ ë§Œê¸°ì¼ í™•ì¸
        expirations = stock.options
        if not expirations:
            return options_info

        options_info["has_options"] = True
        options_info["nearest_expiry"] = expirations[0]

        # í˜„ì¬ê°€
        current_price = stock.info.get('regularMarketPrice', 0) or stock.info.get('currentPrice', 0)

        # ê°€ì¥ ê°€ê¹Œìš´ ë§Œê¸° ì˜µì…˜ ë¶„ì„
        opt = stock.option_chain(expirations[0])
        calls = opt.calls
        puts = opt.puts

        if not calls.empty:
            options_info["total_call_oi"] = int(calls['openInterest'].sum())
            # ITM ì½œ (í–‰ì‚¬ê°€ < í˜„ì¬ê°€)
            itm_calls = calls[calls['strike'] < current_price]
            options_info["itm_calls"] = int(itm_calls['openInterest'].sum()) if not itm_calls.empty else 0

            # ê°ë§ˆ ì§‘ì¤‘ êµ¬ê°„ (OI ë§ì€ í–‰ì‚¬ê°€)
            top_strikes = calls.nlargest(5, 'openInterest')[['strike', 'openInterest']]
            options_info["gamma_exposure"] = [
                {"strike": row['strike'], "oi": int(row['openInterest'])}
                for _, row in top_strikes.iterrows()
            ]

        if not puts.empty:
            options_info["total_put_oi"] = int(puts['openInterest'].sum())

        # Put/Call ë¹„ìœ¨
        if options_info["total_call_oi"] > 0:
            options_info["put_call_ratio"] = round(
                options_info["total_put_oi"] / options_info["total_call_oi"], 2
            )

        # Max Pain ê³„ì‚° (ê°„ë‹¨ ë²„ì „)
        if not calls.empty and not puts.empty:
            all_strikes = sorted(set(calls['strike'].tolist() + puts['strike'].tolist()))
            min_pain = float('inf')
            max_pain_strike = 0

            for strike in all_strikes:
                # ì´ í–‰ì‚¬ê°€ì—ì„œì˜ ì´ ì†ì‹¤
                call_pain = calls[calls['strike'] < strike]['openInterest'].sum() * (strike - calls[calls['strike'] < strike]['strike']).sum() if not calls[calls['strike'] < strike].empty else 0
                put_pain = puts[puts['strike'] > strike]['openInterest'].sum() * (puts[puts['strike'] > strike]['strike'] - strike).sum() if not puts[puts['strike'] > strike].empty else 0
                total_pain = call_pain + put_pain

                if total_pain < min_pain:
                    min_pain = total_pain
                    max_pain_strike = strike

            options_info["max_pain"] = max_pain_strike

    except Exception as e:
        print(f"    âš ï¸ ì˜µì…˜ ë¶„ì„ ì˜¤ë¥˜: {e}")

    return options_info


# ============================================================
# 3.8 ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ (ë‹¤ì¤‘ ì†ŒìŠ¤)
# ============================================================

def get_social_sentiment(ticker: str) -> dict:
    """Stocktwits + Reddit + ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ì„¼í‹°ë¨¼íŠ¸ ìˆ˜ì§‘"""
    sentiment_info = {
        "stocktwits_sentiment": None,
        "stocktwits_messages": 0,
        "trending": False,
        "watchlist_count": 0,
        "recent_posts": [],
        "reddit_mentions": 0,
        "twitter_sentiment": None,
        "overall_sentiment": None,
    }

    bullish_total = 0
    bearish_total = 0

    # 1. Stocktwits
    try:
        url = f"https://api.stocktwits.com/api/2/streams/symbol/{ticker}.json"
        resp = requests.get(url, headers=HEADERS, timeout=10)

        if resp.status_code == 200:
            data = resp.json()

            symbol_data = data.get('symbol', {})
            sentiment_info["watchlist_count"] = symbol_data.get('watchlist_count', 0)
            sentiment_info["trending"] = symbol_data.get('is_following', False)

            messages = data.get('messages', [])
            sentiment_info["stocktwits_messages"] = len(messages)

            bullish = 0
            bearish = 0

            for msg in messages[:20]:
                entities = msg.get('entities', {})
                sent = entities.get('sentiment', {})
                if sent:
                    if sent.get('basic') == 'Bullish':
                        bullish += 1
                    elif sent.get('basic') == 'Bearish':
                        bearish += 1

                if len(sentiment_info["recent_posts"]) < 3:
                    sentiment_info["recent_posts"].append({
                        "body": msg.get('body', '')[:100],
                        "sentiment": sent.get('basic', 'Neutral') if sent else 'Neutral',
                        "source": "Stocktwits"
                    })

            bullish_total += bullish
            bearish_total += bearish

            if bullish > bearish * 1.5:
                sentiment_info["stocktwits_sentiment"] = "Bullish ğŸŸ¢"
            elif bearish > bullish * 1.5:
                sentiment_info["stocktwits_sentiment"] = "Bearish ğŸ”´"
            else:
                sentiment_info["stocktwits_sentiment"] = "Neutral âšª"

    except:
        pass

    # 2. Reddit (wallstreetbets, stocks ë“±) - ì›¹ ìŠ¤í¬ë˜í•‘
    try:
        reddit_url = f"https://www.reddit.com/search.json?q={ticker}&sort=new&limit=10"
        resp = requests.get(reddit_url, headers={
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0"
        }, timeout=10)

        if resp.status_code == 200:
            data = resp.json()
            posts = data.get('data', {}).get('children', [])
            sentiment_info["reddit_mentions"] = len(posts)

            # ì œëª©ì—ì„œ ì„¼í‹°ë¨¼íŠ¸ ì¶”ì •
            for post in posts[:5]:
                title = post.get('data', {}).get('title', '').lower()
                subreddit = post.get('data', {}).get('subreddit', '')

                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì„¼í‹°ë¨¼íŠ¸
                bull_words = ['moon', 'rocket', 'buy', 'calls', 'squeeze', 'bullish', 'long', 'ğŸš€', 'ğŸ’']
                bear_words = ['sell', 'puts', 'short', 'bearish', 'crash', 'dump', 'avoid']

                if any(w in title for w in bull_words):
                    bullish_total += 1
                elif any(w in title for w in bear_words):
                    bearish_total += 1

                if len(sentiment_info["recent_posts"]) < 5:
                    sentiment_info["recent_posts"].append({
                        "body": post.get('data', {}).get('title', '')[:100],
                        "sentiment": "Reddit",
                        "source": f"r/{subreddit}"
                    })

    except:
        pass

    # 3. Finviz ë‰´ìŠ¤ ì„¼í‹°ë¨¼íŠ¸
    try:
        finviz_url = f"https://finviz.com/quote.ashx?t={ticker}"
        resp = requests.get(finviz_url, headers=HEADERS, timeout=10)

        if resp.status_code == 200:
            # Analyst Rating ì¶”ì¶œ
            rating_match = re.search(r'Recom.*?(\d+\.?\d*)', resp.text)
            if rating_match:
                rating = float(rating_match.group(1))
                # 1=Strong Buy, 5=Sell
                if rating <= 2:
                    bullish_total += 2
                elif rating >= 4:
                    bearish_total += 2

    except:
        pass

    # 4. ì¢…í•© ì„¼í‹°ë¨¼íŠ¸ ê²°ì •
    if bullish_total > bearish_total * 1.5:
        sentiment_info["overall_sentiment"] = "ğŸŸ¢ ê°•ì„¸ (Bullish) - ë§¤ìˆ˜ ë¶„ìœ„ê¸°"
    elif bearish_total > bullish_total * 1.5:
        sentiment_info["overall_sentiment"] = "ğŸ”´ ì•½ì„¸ (Bearish) - ë§¤ë„ ë¶„ìœ„ê¸°"
    elif bullish_total > 0 or bearish_total > 0:
        sentiment_info["overall_sentiment"] = "âšª í˜¼ì¡° (Mixed) - ì˜ê²¬ ê°ˆë¦¼"
    else:
        sentiment_info["overall_sentiment"] = "â“ ë°ì´í„° ë¶€ì¡±"

    return sentiment_info


# ============================================================
# 3.9 ì´‰ë§¤(Catalyst) ì¼ì •
# ============================================================

def get_catalyst_calendar(stock) -> dict:
    """ì–´ë‹, FDA, ì»¨í¼ëŸ°ìŠ¤ ë“± ì´‰ë§¤ ì¼ì •"""
    catalyst_info = {
        "next_earnings": None,
        "earnings_estimate": None,
        "recent_earnings_surprise": None,
        "ex_dividend_date": None,
        "upcoming_events": [],
    }

    try:
        info = stock.info

        # ì–´ë‹ ì¼ì •
        earnings_date = info.get('earningsDate')
        if earnings_date:
            if isinstance(earnings_date, list) and earnings_date:
                catalyst_info["next_earnings"] = datetime.fromtimestamp(earnings_date[0]).strftime('%Y-%m-%d')
            elif isinstance(earnings_date, (int, float)):
                catalyst_info["next_earnings"] = datetime.fromtimestamp(earnings_date).strftime('%Y-%m-%d')

        # ì–´ë‹ ì„œí”„ë¼ì´ì¦ˆ
        earnings_hist = stock.earnings_history if hasattr(stock, 'earnings_history') else None
        if earnings_hist is not None and not earnings_hist.empty:
            latest = earnings_hist.iloc[-1] if len(earnings_hist) > 0 else None
            if latest is not None:
                surprise = latest.get('surprisePercent')
                if surprise:
                    catalyst_info["recent_earnings_surprise"] = f"{surprise:.1f}%"

        # ë°°ë‹¹ì¼
        ex_div = info.get('exDividendDate')
        if ex_div:
            catalyst_info["ex_dividend_date"] = datetime.fromtimestamp(ex_div).strftime('%Y-%m-%d')

        # EPS ì¶”ì •ì¹˜
        catalyst_info["earnings_estimate"] = info.get('targetMeanPrice')

    except Exception as e:
        print(f"    âš ï¸ Catalyst ì˜¤ë¥˜: {e}")

    return catalyst_info


# ============================================================
# 3.10 í”¼ë³´ë‚˜ì¹˜ & ì§€ì§€/ì €í•­ ë¶„ì„
# ============================================================

def get_fibonacci_levels(stock) -> dict:
    """í”¼ë³´ë‚˜ì¹˜ ë˜ëŒë¦¼ ë ˆë²¨ ê³„ì‚°"""
    fib_info = {
        "levels": {},
        "current_zone": None,
        "support_levels": [],
        "resistance_levels": [],
        "gaps": [],
    }

    try:
        # ìµœê·¼ 6ê°œì›” ë°ì´í„°
        hist = stock.history(period="6mo")
        if hist.empty:
            return fib_info

        high = hist['High'].max()
        low = hist['Low'].min()
        current = hist['Close'].iloc[-1]
        diff = high - low

        # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨
        fib_levels = {
            "0%": high,
            "23.6%": high - diff * 0.236,
            "38.2%": high - diff * 0.382,
            "50%": high - diff * 0.5,
            "61.8%": high - diff * 0.618,
            "78.6%": high - diff * 0.786,
            "100%": low,
        }
        fib_info["levels"] = {k: round(v, 2) for k, v in fib_levels.items()}

        # í˜„ì¬ ìœ„ì¹˜ ë¶„ì„
        for level_name, level_price in fib_levels.items():
            if current >= level_price:
                fib_info["current_zone"] = f"{level_name} ìœ„"
                break

        # ì§€ì§€ì„ /ì €í•­ì„  (í˜„ì¬ê°€ ê¸°ì¤€)
        for level_name, level_price in fib_levels.items():
            if level_price < current:
                fib_info["support_levels"].append({
                    "level": level_name,
                    "price": round(level_price, 2),
                    "distance": f"{((current - level_price) / current * 100):.1f}%"
                })
            elif level_price > current:
                fib_info["resistance_levels"].append({
                    "level": level_name,
                    "price": round(level_price, 2),
                    "distance": f"{((level_price - current) / current * 100):.1f}%"
                })

        # ê°­ ë¶„ì„ (ìµœê·¼ 20ì¼)
        recent = hist.tail(20)
        for i in range(1, len(recent)):
            prev_close = recent['Close'].iloc[i-1]
            curr_open = recent['Open'].iloc[i]
            curr_high = recent['High'].iloc[i]
            curr_low = recent['Low'].iloc[i]

            # ê°­ì—…
            if curr_open > prev_close * 1.02:
                gap_filled = curr_low <= prev_close
                fib_info["gaps"].append({
                    "type": "ê°­ì—…",
                    "date": str(recent.index[i].date()),
                    "gap_start": round(prev_close, 2),
                    "gap_end": round(curr_open, 2),
                    "filled": "ì¶©ì „ë¨" if gap_filled else "ë¯¸ì¶©ì „"
                })
            # ê°­ë‹¤ìš´
            elif curr_open < prev_close * 0.98:
                gap_filled = curr_high >= prev_close
                fib_info["gaps"].append({
                    "type": "ê°­ë‹¤ìš´",
                    "date": str(recent.index[i].date()),
                    "gap_start": round(curr_open, 2),
                    "gap_end": round(prev_close, 2),
                    "filled": "ì¶©ì „ë¨" if gap_filled else "ë¯¸ì¶©ì „"
                })

    except Exception as e:
        print(f"    âš ï¸ í”¼ë³´ë‚˜ì¹˜ ì˜¤ë¥˜: {e}")

    return fib_info


# ============================================================
# 3.11 ë³¼ë¥¨ í”„ë¡œíŒŒì¼
# ============================================================

def get_volume_profile(stock) -> dict:
    """ê°€ê²©ëŒ€ë³„ ê±°ë˜ëŸ‰ ë¶„ì„"""
    vp_info = {
        "high_volume_zones": [],
        "poc": None,  # Point of Control (ê°€ì¥ ê±°ë˜ëŸ‰ ë§ì€ ê°€ê²©ëŒ€)
        "value_area_high": None,
        "value_area_low": None,
    }

    try:
        hist = stock.history(period="3mo")
        if hist.empty or len(hist) < 20:
            return vp_info

        # ê°€ê²© êµ¬ê°„ ìƒì„± (20ê°œ êµ¬ê°„)
        price_min = hist['Low'].min()
        price_max = hist['High'].max()
        num_bins = 20
        bin_size = (price_max - price_min) / num_bins

        volume_by_price = {}

        for i in range(len(hist)):
            avg_price = (hist['High'].iloc[i] + hist['Low'].iloc[i]) / 2
            volume = hist['Volume'].iloc[i]

            bin_idx = int((avg_price - price_min) / bin_size)
            bin_idx = min(bin_idx, num_bins - 1)
            bin_price = price_min + bin_idx * bin_size + bin_size / 2

            if bin_price not in volume_by_price:
                volume_by_price[bin_price] = 0
            volume_by_price[bin_price] += volume

        if volume_by_price:
            # POC (Point of Control)
            poc_price = max(volume_by_price, key=volume_by_price.get)
            vp_info["poc"] = round(poc_price, 2)

            # ìƒìœ„ ê±°ë˜ëŸ‰ êµ¬ê°„
            sorted_zones = sorted(volume_by_price.items(), key=lambda x: x[1], reverse=True)
            vp_info["high_volume_zones"] = [
                {"price": round(price, 2), "volume": int(vol)}
                for price, vol in sorted_zones[:5]
            ]

            # Value Area (ê±°ë˜ëŸ‰ 70% êµ¬ê°„)
            total_vol = sum(volume_by_price.values())
            target_vol = total_vol * 0.7
            cumulative = 0

            # POCì—ì„œ ì‹œì‘í•´ì„œ í™•ì¥
            va_prices = [poc_price]
            remaining = {k: v for k, v in volume_by_price.items() if k != poc_price}
            cumulative = volume_by_price[poc_price]

            while cumulative < target_vol and remaining:
                next_price = max(remaining, key=remaining.get)
                va_prices.append(next_price)
                cumulative += remaining[next_price]
                del remaining[next_price]

            vp_info["value_area_high"] = round(max(va_prices), 2)
            vp_info["value_area_low"] = round(min(va_prices), 2)

    except Exception as e:
        print(f"    âš ï¸ ë³¼ë¥¨ í”„ë¡œíŒŒì¼ ì˜¤ë¥˜: {e}")

    return vp_info


# ============================================================
# 3.12 ë‹¤í¬í’€ & ì¥ì™¸ê±°ë˜ (ë‹¤ì¤‘ ì†ŒìŠ¤)
# ============================================================

def get_darkpool_data(ticker: str) -> dict:
    """ë‹¤í¬í’€/ìˆë³¼ë¥¨ ë°ì´í„° (ì—¬ëŸ¬ ì†ŒìŠ¤)"""
    dp_info = {
        "darkpool_volume": 0,
        "darkpool_trades": 0,
        "dp_percent": 0,
        "short_volume_percent": 0,
        "off_exchange_percent": 0,
        "recent_dp_data": [],
        "source": None,
    }

    # 1. Chartexchange ì‹œë„
    try:
        ce_url = f"https://chartexchange.com/symbol/nasdaq-{ticker.lower()}/"
        resp = requests.get(ce_url, headers=HEADERS, timeout=10)

        if resp.status_code == 200:
            text = resp.text.lower()

            # Short Volume ë¹„ìœ¨
            sv_match = re.search(r'short\s*(?:volume|vol)[:\s]*(\d+\.?\d*)%', text)
            if sv_match:
                dp_info["short_volume_percent"] = float(sv_match.group(1))
                dp_info["source"] = "Chartexchange"

            # Off-exchange (ë‹¤í¬í’€) ë¹„ìœ¨
            oe_match = re.search(r'off[- ]?exchange[:\s]*(\d+\.?\d*)%', text)
            if oe_match:
                dp_info["off_exchange_percent"] = float(oe_match.group(1))

            # Dark Pool Volume
            dp_vol_match = re.search(r'dark\s*pool\s*(?:volume)?[:\s]*([\d,]+)', text)
            if dp_vol_match:
                dp_info["darkpool_volume"] = int(dp_vol_match.group(1).replace(',', ''))

    except:
        pass

    # 2. Fintel ë°±ì—… ì‹œë„
    if not dp_info["short_volume_percent"]:
        try:
            fintel_url = f"https://fintel.io/ss/us/{ticker.lower()}"
            resp = requests.get(fintel_url, headers=HEADERS, timeout=10)

            if resp.status_code == 200:
                text = resp.text.lower()

                # Short Volume Ratio
                sv_match = re.search(r'short\s*volume\s*ratio[:\s]*(\d+\.?\d*)%', text)
                if sv_match:
                    dp_info["short_volume_percent"] = float(sv_match.group(1))
                    dp_info["source"] = "Fintel"

        except:
            pass

    # 3. Stocksera ë°±ì—… (ë¬´ë£Œ API)
    if not dp_info["short_volume_percent"]:
        try:
            stocksera_url = f"https://stocksera.pythonanywhere.com/api/short_volume/{ticker}"
            resp = requests.get(stocksera_url, timeout=10)

            if resp.status_code == 200:
                data = resp.json()
                if data and len(data) > 0:
                    latest = data[0]
                    total = latest.get('total_volume', 0)
                    short = latest.get('short_volume', 0)
                    if total > 0:
                        dp_info["short_volume_percent"] = round((short / total) * 100, 1)
                        dp_info["source"] = "Stocksera"

        except:
            pass

    # 4. ê²½ê³  ìˆ˜ì¤€ íŒë‹¨
    if dp_info["short_volume_percent"] > 50:
        dp_info["warning"] = "âš ï¸ ìˆ ë³¼ë¥¨ 50% ì´ˆê³¼ - ìˆ ì••ë ¥ ë†’ìŒ"
    elif dp_info["short_volume_percent"] > 30:
        dp_info["warning"] = "ğŸŸ¡ ìˆ ë³¼ë¥¨ 30%+ - ì£¼ì˜"

    if dp_info["off_exchange_percent"] > 50:
        dp_info["dp_warning"] = "âš ï¸ ì¥ì™¸ê±°ë˜ 50% ì´ˆê³¼ - ë‹¤í¬í’€ í™œë°œ"

    return dp_info


# ============================================================
# 3.13 SEC Filing íŒŒì‹± (S-1, 10-K ë“±) - ê°œì„ íŒ
# ============================================================

def get_sec_filings(ticker: str) -> dict:
    """SEC EDGARì—ì„œ ìµœê·¼ filing ëª©ë¡ ë° ì£¼ìš” ë‚´ìš© (ê°œì„ íŒ)"""
    filings_info = {
        "recent_filings": [],
        "lockup_info": None,
        "warrant_details": [],
        "debt_details": [],
        "insider_lockup_price": None,
        "offering_info": [],
        "company_name": None,
        "cik": None,
        # SPAC ê´€ë ¨
        "is_spac": False,
        "spac_merger_date": None,
        "earnout_conditions": [],
        "earnout_prices": [],
        "earnout_shares": None,
    }

    headers = {"User-Agent": "DailyStockStory/1.0 (sean@example.com)"}

    try:
        cik = None

        # 1. SEC ê³µì‹ í‹°ì»¤-CIK ë§¤í•‘ JSON ì‚¬ìš© (ê°€ì¥ ì •í™•!)
        try:
            tickers_url = "https://www.sec.gov/files/company_tickers.json"
            resp = requests.get(tickers_url, headers=headers, timeout=15)
            if resp.status_code == 200:
                tickers_data = resp.json()
                for key, company in tickers_data.items():
                    if company.get('ticker', '').upper() == ticker.upper():
                        cik = str(company.get('cik_str', '')).zfill(10)
                        filings_info["company_name"] = company.get('title')
                        break
        except:
            pass

        # 2. ë°±ì—…: EDGAR ê²€ìƒ‰
        if not cik:
            try:
                ticker_url = f"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={ticker}&type=&dateb=&owner=include&count=10&output=atom"
                resp = requests.get(ticker_url, headers=headers, timeout=15)
                cik_match = re.search(r'CIK=(\d+)', resp.text)
                if cik_match:
                    cik = cik_match.group(1).zfill(10)
            except:
                pass

        if not cik:
            return filings_info
        filings_info["cik"] = cik

        # 2. ìµœê·¼ filings ê°€ì ¸ì˜¤ê¸° (JSON API)
        filings_url = f"https://data.sec.gov/submissions/CIK{cik}.json"
        resp = requests.get(filings_url, headers=headers, timeout=15)

        if resp.status_code == 200:
            data = resp.json()
            filings_info["company_name"] = data.get('name')

            recent = data.get('filings', {}).get('recent', {})

            forms = recent.get('form', [])
            dates = recent.get('filingDate', [])
            accessions = recent.get('accessionNumber', [])
            descriptions = recent.get('primaryDocument', [])

            # ê´€ì‹¬ ìˆëŠ” form íƒ€ì… (SPAC ê´€ë ¨ S-4, DEFM14A ì¶”ê°€)
            important_forms = ["S-1", "S-1/A", "S-3", "S-4", "S-4/A", "424B4", "424B5", "10-K", "10-Q", "8-K", "DEF 14A", "DEFM14A"]

            for i in range(min(30, len(forms))):
                form_type = forms[i]
                if form_type in important_forms or len(filings_info["recent_filings"]) < 10:
                    filings_info["recent_filings"].append({
                        "form": form_type,
                        "date": dates[i],
                        "accession": accessions[i].replace('-', ''),
                        "document": descriptions[i] if i < len(descriptions) else ""
                    })

            # 3. ì£¼ìš” ë¬¸ì„œì—ì„œ ì •ë³´ ì¶”ì¶œ
            for filing in filings_info["recent_filings"][:5]:
                form_type = filing["form"]

                # S-1, S-4, 424B, DEF 14A, DEFM14Aì—ì„œ ë½ì—…/ì›ŒëŸ°íŠ¸/ë¹š/earnout ì •ë³´ ì°¾ê¸°
                if form_type in ["S-1", "S-1/A", "S-4", "S-4/A", "424B4", "424B5", "DEF 14A", "DEFM14A", "10-K"]:
                    try:
                        # ë¬¸ì„œ URL ìƒì„±
                        acc_formatted = filing['accession']
                        doc_url = f"https://www.sec.gov/Archives/edgar/data/{cik.lstrip('0')}/{acc_formatted}/{filing['document']}"

                        doc_resp = requests.get(doc_url, headers=headers, timeout=20)

                        if doc_resp.status_code == 200:
                            doc_text = doc_resp.text.lower()

                            # Lock-up ê°€ê²©/ê¸°ê°„ ì°¾ê¸° (ë” ë§ì€ íŒ¨í„´)
                            if not filings_info["insider_lockup_price"]:
                                lockup_patterns = [
                                    # ê°€ê²© ê¸°ë°˜ ë½ì—… (SPAC ìŠ¤íƒ€ì¼)
                                    r'lock-?up.*?(?:release[sd]?|terminate[sd]?).*?(?:stock\s*)?price.*?(?:equals?\s*or\s*)?exceeds?\s*\$?([\d,]+\.?\d*)',
                                    r'(?:lock-?up|restriction).*?(?:expire[sd]?|release[sd]?).*?(?:when|if).*?\$([\d,]+\.?\d*)',
                                    # ì „í†µì  ë½ì—…
                                    r'lock-?up.*?(?:price|until).*?(\$[\d,]+\.?\d*)',
                                    r'may not (?:sell|transfer).*?until.*?(?:closing price|stock price).*?(\$[\d,]+\.?\d*)',
                                    r'(?:180|90|365)\s*days?\s*(?:after|following).*?ipo',
                                    r'insider.*?lock.*?(\$[\d,]+\.?\d*)',
                                    r'(?:founder|insider|officer|sponsor).*?(?:may not sell|restricted|cannot transfer).*?(\$[\d,]+)',
                                    # ì£¼ê°€ ì¡°ê±´ë¶€ ë½ì—…
                                    r'(?:shares?|stock).*?(?:released?|unlocked?).*?(?:if|when).*?price.*?(?:reaches?|exceeds?|equals?)\s*\$?([\d,]+\.?\d*)',
                                    r'(?:restriction|lock-?up).*?(?:waived?|removed?).*?(?:stock\s*)?price.*?\$?([\d,]+\.?\d*)',
                                ]

                                for pattern in lockup_patterns:
                                    match = re.search(pattern, doc_text)
                                    if match:
                                        if match.groups() and match.group(1):
                                            price_str = match.group(1).replace(',', '')
                                            try:
                                                price_val = float(price_str)
                                                if 10 <= price_val <= 500:  # í•©ë¦¬ì ì¸ ê°€ê²© ë²”ìœ„
                                                    filings_info["insider_lockup_price"] = f"${price_val}"
                                                    break
                                            except:
                                                pass
                                        else:
                                            filings_info["lockup_info"] = "180ì¼ ë½ì—… ì¡´ì¬"
                                            break

                            # ì›ŒëŸ°íŠ¸ ì •ë³´ (ë” ë§ì€ íŒ¨í„´)
                            if not filings_info["warrant_details"]:
                                warrant_patterns = [
                                    r'warrant.*?exercise\s*price.*?(\$[\d,]+\.?\d*)',
                                    r'warrants?\s*(?:to purchase|exercisable).*?(\$[\d,]+\.?\d*)',
                                    r'exercise\s*price\s*(?:of|is)\s*(\$[\d,]+\.?\d*)\s*per\s*share',
                                ]

                                for pattern in warrant_patterns:
                                    matches = re.findall(pattern, doc_text)
                                    if matches:
                                        filings_info["warrant_details"] = list(set(matches))[:5]
                                        break

                            # ë¹š/Debt ì •ë³´
                            if not filings_info["debt_details"]:
                                debt_patterns = [
                                    r'(credit facility|term loan|senior note|convertible note).*?(\$[\d,]+\.?\d*\s*(?:million|billion)?)',
                                    r'(indebtedness|borrowing).*?(\$[\d,]+\.?\d*\s*(?:million|billion)?)',
                                    r'outstanding\s*(debt|loan).*?(\$[\d,]+\.?\d*\s*(?:million|billion)?)',
                                ]

                                for pattern in debt_patterns:
                                    matches = re.findall(pattern, doc_text)
                                    if matches:
                                        filings_info["debt_details"] = [
                                            f"{m[0].title()}: {m[1]}" for m in matches[:5]
                                        ]
                                        break

                            # Offering ì •ë³´ (S-3, 424B)
                            if form_type in ["S-3", "424B4", "424B5"]:
                                offering_match = re.search(r'(?:offering|issuance).*?(\d[\d,]*)\s*shares.*?(\$[\d,]+\.?\d*)', doc_text)
                                if offering_match:
                                    filings_info["offering_info"].append({
                                        "shares": offering_match.group(1),
                                        "price": offering_match.group(2),
                                        "date": filing["date"],
                                        "form": form_type
                                    })

                            # SPAC / Earnout ì •ë³´ (S-4, DEFM14A, 8-K)
                            if form_type in ["S-4", "S-4/A", "DEFM14A", "8-K"]:
                                # SPAC ì—¬ë¶€ ê°ì§€
                                spac_keywords = ['business combination', 'spac', 'blank check', 'de-spac', 'merger agreement']
                                if any(kw in doc_text for kw in spac_keywords):
                                    filings_info["is_spac"] = True

                                # Earnout ì¡°ê±´ ì°¾ê¸°
                                earnout_patterns = [
                                    # "closing price equals or exceeds $X for Y trading days"
                                    r'(?:closing|stock)\s*price\s*(?:equals?\s*or\s*)?exceeds?\s*\$?([\d,]+\.?\d*)\s*(?:per\s*share\s*)?(?:for|during)\s*(\d+)\s*(?:trading\s*)?days?',
                                    # "VWAP exceeds $X"
                                    r'vwap\s*(?:equals?\s*or\s*)?exceeds?\s*\$?([\d,]+\.?\d*)',
                                    # "stock price reaches $X"
                                    r'stock\s*price\s*(?:of\s*the\s*company\s*)?reaches?\s*\$?([\d,]+\.?\d*)',
                                    # "earnout shares... $X"
                                    r'earnout\s*shares?.*?\$?([\d,]+\.?\d*)\s*(?:per\s*share)?',
                                    # "if the price... exceeds $X"
                                    r'if\s*(?:the\s*)?(?:closing\s*)?price.*?exceeds?\s*\$?([\d,]+\.?\d*)',
                                ]

                                for pattern in earnout_patterns:
                                    matches = re.findall(pattern, doc_text)
                                    for match in matches:
                                        if isinstance(match, tuple):
                                            price = match[0]
                                        else:
                                            price = match
                                        try:
                                            price_val = float(price.replace(',', ''))
                                            if 10 <= price_val <= 500:  # í•©ë¦¬ì ì¸ ê°€ê²© ë²”ìœ„
                                                if f"${price_val}" not in filings_info["earnout_prices"]:
                                                    filings_info["earnout_prices"].append(f"${price_val}")
                                        except:
                                            pass

                                # Earnout ì£¼ì‹ ìˆ˜ ì°¾ê¸°
                                earnout_shares_patterns = [
                                    r'(\d[\d,]*)\s*(?:earnout|contingent)\s*shares?',
                                    r'(?:earnout|contingent)\s*shares?\s*(?:of\s*)?(\d[\d,]*)',
                                    r'up\s*to\s*(\d[\d,]*)\s*additional\s*shares?',
                                ]
                                for pattern in earnout_shares_patterns:
                                    match = re.search(pattern, doc_text)
                                    if match:
                                        filings_info["earnout_shares"] = match.group(1)
                                        break

                                # ë½ì—… ì¡°ê±´ (SPAC íŠ¹í™”)
                                spac_lockup_patterns = [
                                    r'(?:founder|sponsor|insider)\s*shares?.*?(?:lock-?up|may\s*not\s*(?:sell|transfer)).*?(?:until|unless).*?(?:stock\s*)?price.*?\$?([\d,]+\.?\d*)',
                                    r'(?:lock-?up|restriction).*?(?:released?|terminate[sd]?).*?(?:stock\s*)?price.*?(?:equals?\s*or\s*)?exceeds?\s*\$?([\d,]+\.?\d*)',
                                    r'shares?\s*(?:may\s*)?(?:not\s*)?(?:be\s*)?(?:sold|transferred).*?until.*?(?:\$|price\s*of\s*)([\d,]+\.?\d*)',
                                ]
                                for pattern in spac_lockup_patterns:
                                    match = re.search(pattern, doc_text)
                                    if match and not filings_info["insider_lockup_price"]:
                                        try:
                                            price_val = float(match.group(1).replace(',', ''))
                                            if 10 <= price_val <= 500:
                                                filings_info["insider_lockup_price"] = f"${price_val}"
                                        except:
                                            pass

                    except Exception as e:
                        pass  # ê°œë³„ ë¬¸ì„œ íŒŒì‹± ì‹¤íŒ¨ëŠ” ë¬´ì‹œ

    except Exception as e:
        print(f"    âš ï¸ SEC Filing íŒŒì‹± ì˜¤ë¥˜: {e}")

    return filings_info


# ============================================================
# 3.14 ê¸°ê´€ ë³´ìœ  ë³€í™” (13F)
# ============================================================

def get_institutional_changes(stock) -> dict:
    """ê¸°ê´€ ë³´ìœ  ë³€í™” ë¶„ì„"""
    inst_info = {
        "total_institutional": 0,
        "top_holders": [],
        "recent_changes": [],
        "net_institutional_change": "unknown",
    }

    try:
        # yfinance ê¸°ê´€ ë³´ìœ 
        holders = stock.institutional_holders
        if holders is not None and not holders.empty:
            inst_info["total_institutional"] = len(holders)

            for _, row in holders.head(5).iterrows():
                inst_info["top_holders"].append({
                    "holder": row.get('Holder', 'N/A'),
                    "shares": int(row.get('Shares', 0)),
                    "value": int(row.get('Value', 0)),
                    "pct_out": f"{row.get('pctHeld', 0) * 100:.2f}%" if row.get('pctHeld') else 'N/A'
                })

        # ê¸°ê´€ ë³´ìœ  ë¹„ìœ¨
        info = stock.info
        inst_pct = info.get('heldPercentInstitutions')
        if inst_pct:
            inst_info["institutional_percent"] = f"{inst_pct * 100:.1f}%"

    except Exception as e:
        print(f"    âš ï¸ ê¸°ê´€ ë³´ìœ  ë¶„ì„ ì˜¤ë¥˜: {e}")

    return inst_info


# ============================================================
# 3.15 ë™ì¢…ì—…ì²´ ë¹„êµ
# ============================================================

def get_peer_comparison(stock, ticker: str) -> dict:
    """ë™ì¢…ì—…ì²´ ë¹„êµ ë¶„ì„"""
    peer_info = {
        "sector": None,
        "industry": None,
        "peers": [],
        "sector_avg_pe": None,
        "relative_valuation": None,
    }

    try:
        info = stock.info
        peer_info["sector"] = info.get('sector')
        peer_info["industry"] = info.get('industry')

        my_pe = info.get('trailingPE')
        my_pb = info.get('priceToBook')
        my_ps = info.get('priceToSalesTrailing12Months')

        # ì„¹í„° í‰ê·  (yfinanceëŠ” peers ì œê³µ ì•ˆí•¨, ëŒ€ì‹  sector í‰ê·  ì¶”ì •)
        sector_pe_avg = {
            "Technology": 25,
            "Healthcare": 20,
            "Financial Services": 12,
            "Consumer Cyclical": 18,
            "Communication Services": 20,
            "Industrials": 16,
            "Energy": 10,
            "Basic Materials": 12,
            "Consumer Defensive": 22,
            "Real Estate": 35,
            "Utilities": 18,
        }

        sector = info.get('sector')
        if sector and sector in sector_pe_avg:
            peer_info["sector_avg_pe"] = sector_pe_avg[sector]

            if my_pe and my_pe > 0:
                ratio = my_pe / sector_pe_avg[sector]
                if ratio > 1.5:
                    peer_info["relative_valuation"] = "ê³ í‰ê°€ âš ï¸"
                elif ratio < 0.7:
                    peer_info["relative_valuation"] = "ì €í‰ê°€ ğŸ’°"
                else:
                    peer_info["relative_valuation"] = "ì ì •"
            else:
                peer_info["relative_valuation"] = "ì ìê¸°ì—… (PE ì—†ìŒ)"

    except Exception as e:
        print(f"    âš ï¸ ë™ì¢…ì—…ì²´ ë¹„êµ ì˜¤ë¥˜: {e}")

    return peer_info


# ============================================================
# 3.16 Short Interest íˆìŠ¤í† ë¦¬
# ============================================================

def get_short_history(ticker: str) -> dict:
    """Short Interest ë³€í™” ì¶”ì´ (ì—¬ëŸ¬ ì†ŒìŠ¤ ì‹œë„)"""
    short_hist = {
        "history": [],
        "trend": "unknown",
        "change_30d": None,
        "current_si": None,
        "prior_si": None,
    }

    try:
        # 1. yfinanceì—ì„œ ê¸°ë³¸ Short ë°ì´í„°
        stock = yf.Ticker(ticker)
        info = stock.info

        current = info.get('sharesShort')
        prior = info.get('sharesShortPriorMonth')

        if current:
            short_hist["current_si"] = current
        if prior:
            short_hist["prior_si"] = prior

        # ë³€í™”ìœ¨ ê³„ì‚°
        if current and prior and prior > 0:
            change = ((current - prior) / prior) * 100
            short_hist["change_30d"] = f"{change:+.1f}%"

            if change > 50:
                short_hist["trend"] = "ê¸‰ì¦ ğŸ“ˆğŸ”¥"
            elif change > 20:
                short_hist["trend"] = "ê¸‰ì¦ ğŸ“ˆ"
            elif change > 5:
                short_hist["trend"] = "ì¦ê°€ â†—ï¸"
            elif change < -30:
                short_hist["trend"] = "ê¸‰ê° ğŸ“‰ (ì»¤ë²„ë§?)"
            elif change < -10:
                short_hist["trend"] = "ê°ì†Œ â†˜ï¸"
            else:
                short_hist["trend"] = "ì•ˆì •"

            # íˆìŠ¤í† ë¦¬ ì¶”ê°€
            short_hist["history"].append({
                "date": "í˜„ì¬",
                "short_interest": current,
            })
            short_hist["history"].append({
                "date": "ì „ì›”",
                "short_interest": prior,
            })

        # 2. Finvizì—ì„œ ì¶”ê°€ ë°ì´í„° ì‹œë„
        try:
            finviz_url = f"https://finviz.com/quote.ashx?t={ticker}"
            resp = requests.get(finviz_url, headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }, timeout=10)

            if resp.status_code == 200:
                # Short Float % ì¶”ì¶œ
                match = re.search(r'Short Float.*?(\d+\.?\d*)%', resp.text)
                if match:
                    short_hist["short_float_pct"] = f"{match.group(1)}%"

                # Short Ratio ì¶”ì¶œ
                match2 = re.search(r'Short Ratio.*?(\d+\.?\d*)', resp.text)
                if match2:
                    short_hist["short_ratio"] = float(match2.group(1))

        except:
            pass

        # 3. Chartexchange ë°±ì—…
        try:
            ce_url = f"https://chartexchange.com/symbol/nasdaq-{ticker.lower()}/"
            resp = requests.get(ce_url, headers=HEADERS, timeout=10)

            if resp.status_code == 200:
                # Short Volume ì¶”ì¶œ
                sv_match = re.search(r'short\s*volume[:\s]*(\d[\d,]*)', resp.text.lower())
                if sv_match:
                    short_hist["short_volume"] = sv_match.group(1).replace(',', '')

        except:
            pass

    except Exception as e:
        print(f"    âš ï¸ Short History ì˜¤ë¥˜: {e}")

    return short_hist


# ============================================================
# 4. RegSHO Threshold List
# ============================================================

def check_regsho(ticker: str) -> bool:
    """DB ë˜ëŠ” NASDAQì—ì„œ RegSHO í™•ì¸"""
    # DB ì²´í¬
    try:
        conn = get_db()
        if conn:
            cur = conn.cursor()
            cur.execute("""
                SELECT 1 FROM regsho_list
                WHERE ticker = %s AND collected_at > NOW() - INTERVAL '7 days'
                LIMIT 1
            """, (ticker,))
            result = cur.fetchone()
            conn.close()
            if result:
                return True
    except:
        pass

    # NASDAQ ì§ì ‘ ì²´í¬
    try:
        url = "https://www.nasdaqtrader.com/dynamic/symdir/regsho/nasdaqth.txt"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        if ticker.upper() in resp.text.upper():
            return True
    except:
        pass

    return False


# ============================================================
# 5. ê¸°ìˆ ì  ì§€í‘œ
# ============================================================

def get_technicals(stock) -> dict:
    """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
    try:
        hist = stock.history(period="3mo")

        if hist.empty:
            return {}

        close = hist["Close"]
        high = hist["High"]
        low = hist["Low"]
        volume = hist["Volume"]

        # RSI (14ì¼)
        delta = close.diff()
        gain = delta.where(delta > 0, 0).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))

        # MACD
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        macd = ema12 - ema26
        signal = macd.ewm(span=9, adjust=False).mean()
        macd_hist = macd - signal

        # ë³¼ë¦°ì € ë°´ë“œ
        sma20 = close.rolling(window=20).mean()
        std20 = close.rolling(window=20).std()
        bb_upper = sma20 + (std20 * 2)
        bb_lower = sma20 - (std20 * 2)

        current = close.iloc[-1]
        bb_position = ((current - bb_lower.iloc[-1]) / (bb_upper.iloc[-1] - bb_lower.iloc[-1])) * 100 if bb_upper.iloc[-1] != bb_lower.iloc[-1] else 50

        # ATR
        tr = pd.concat([
            high - low,
            abs(high - close.shift()),
            abs(low - close.shift())
        ], axis=1).max(axis=1)
        atr = tr.rolling(window=14).mean()

        # ê±°ë˜ëŸ‰ ë¹„ìœ¨
        vol_ratio = volume.iloc[-1] / volume.rolling(window=20).mean().iloc[-1] if volume.rolling(window=20).mean().iloc[-1] > 0 else 1

        return {
            "rsi": rsi.iloc[-1],
            "macd": macd.iloc[-1],
            "macd_signal": signal.iloc[-1],
            "macd_hist": macd_hist.iloc[-1],
            "bb_upper": bb_upper.iloc[-1],
            "bb_middle": sma20.iloc[-1],
            "bb_lower": bb_lower.iloc[-1],
            "bb_position": bb_position,
            "atr": atr.iloc[-1],
            "atr_pct": (atr.iloc[-1] / current) * 100,
            "vol_ratio": vol_ratio,
            "sma_20": sma20.iloc[-1],
            "sma_50": close.rolling(window=50).mean().iloc[-1] if len(close) >= 50 else None,
            # ê°€ê²© ë³€í™”
            "change_1d": ((close.iloc[-1] / close.iloc[-2]) - 1) * 100 if len(close) >= 2 else 0,
            "change_5d": ((close.iloc[-1] / close.iloc[-5]) - 1) * 100 if len(close) >= 5 else 0,
            "change_20d": ((close.iloc[-1] / close.iloc[-20]) - 1) * 100 if len(close) >= 20 else 0,
        }
    except Exception as e:
        print(f"  âš ï¸ ê¸°ìˆ ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {}


# ============================================================
# 6. ê²½ì˜ì§„ & ë‚´ë¶€ì
# ============================================================

def get_officers(stock) -> list:
    """ê²½ì˜ì§„ ì •ë³´"""
    try:
        return stock.info.get("companyOfficers", [])
    except:
        return []


def get_insider_transactions(stock) -> list:
    """ë‚´ë¶€ì ê±°ë˜"""
    try:
        insider = stock.insider_transactions
        if insider is not None and not insider.empty:
            return insider.to_dict('records')
        return []
    except:
        return []


def get_institutional_holders(stock) -> list:
    """ê¸°ê´€ ë³´ìœ """
    try:
        holders = stock.institutional_holders
        if holders is not None and not holders.empty:
            return holders.to_dict('records')
        return []
    except:
        return []


# ============================================================
# 7. ë‰´ìŠ¤ ìˆ˜ì§‘
# ============================================================

def get_news(stock) -> list:
    """yfinance ë‰´ìŠ¤"""
    try:
        news = stock.news
        return news[:10] if news else []
    except:
        return []


def search_recent_news(ticker: str, days: int = 60) -> list:
    """êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ (ìµœê·¼ Nì¼ í•„í„°)"""
    try:
        from datetime import datetime, timedelta
        cutoff_date = datetime.now() - timedelta(days=days)

        url = f"https://news.google.com/rss/search?q={ticker}+stock&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        news = []
        for item in soup.find_all("item")[:15]:
            title = item.find("title")
            link = item.find("link")
            pub_date = item.find("pubDate")

            if title:
                # ë‚ ì§œ íŒŒì‹± ë° í•„í„°ë§
                date_str = pub_date.text if pub_date else ""
                try:
                    # "Wed, 22 Jan 2026 10:00:00 GMT" í˜•ì‹
                    parsed_date = datetime.strptime(date_str[:16], "%a, %d %b %Y")
                    if parsed_date < cutoff_date:
                        continue  # ì˜¤ë˜ëœ ë‰´ìŠ¤ ìŠ¤í‚µ
                except:
                    pass

                news.append({
                    "title": title.text,
                    "link": link.text if link else "",
                    "date": date_str
                })
        return news[:10]
    except:
        return []


# ============================================================
# ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤ ìˆ˜ì§‘
# ============================================================

def get_sector_news(ticker: str, sector: str, industry: str) -> dict:
    """ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤ ìˆ˜ì§‘ (ìµœê·¼ 60ì¼)"""
    sector_news = {
        "general_news": [],
        "sector_specific": [],
        "catalysts": [],
        "source": None,
    }

    sector_lower = (sector or "").lower()
    industry_lower = (industry or "").lower()

    # 1. ì¼ë°˜ êµ¬ê¸€ ë‰´ìŠ¤ (ë°±ì—…)
    sector_news["general_news"] = search_recent_news(ticker, days=60)

    # 2. ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤
    if "biotech" in industry_lower or "pharma" in industry_lower or "healthcare" in sector_lower:
        sector_news["sector_specific"] = get_biotech_news(ticker)
        sector_news["source"] = "ğŸ§¬ Biotech"
    elif "software" in industry_lower or "semiconductor" in industry_lower or "technology" in sector_lower:
        sector_news["sector_specific"] = get_tech_news(ticker)
        sector_news["source"] = "ğŸ¤– Tech/AI"
    elif "energy" in sector_lower or "oil" in industry_lower or "gas" in industry_lower:
        sector_news["sector_specific"] = get_energy_news(ticker)
        sector_news["source"] = "â›½ Energy"
    elif "auto" in industry_lower or "vehicle" in industry_lower or "ev" in industry_lower:
        sector_news["sector_specific"] = get_automotive_news(ticker)
        sector_news["source"] = "ğŸš— Automotive"
    elif "real estate" in sector_lower or "reit" in industry_lower:
        # REIT ì²´í¬ë¥¼ retail ì•ì— (REIT - Retail êµ¬ë¶„)
        sector_news["sector_specific"] = get_realestate_news(ticker)
        sector_news["source"] = "ğŸ  Real Estate"
    elif "retail" in industry_lower or "e-commerce" in industry_lower or "store" in industry_lower:
        sector_news["sector_specific"] = get_retail_news(ticker)
        sector_news["source"] = "ğŸ›’ Retail"
    elif "food" in industry_lower or "beverage" in industry_lower or "consumer" in sector_lower:
        sector_news["sector_specific"] = get_consumer_news(ticker)
        sector_news["source"] = "ğŸ” Consumer"
    elif "bank" in industry_lower or "financial" in sector_lower or "insurance" in industry_lower:
        sector_news["sector_specific"] = get_financial_news(ticker)
        sector_news["source"] = "ğŸ¦ Financial"
    elif "industrial" in sector_lower or "aerospace" in industry_lower or "defense" in industry_lower:
        sector_news["sector_specific"] = get_industrial_news(ticker)
        sector_news["source"] = "ğŸ­ Industrial"
    else:
        # ê¸°ë³¸: Finviz ë‰´ìŠ¤
        sector_news["sector_specific"] = get_finviz_news(ticker)
        sector_news["source"] = "ğŸ“° General"

    return sector_news


def get_biotech_news(ticker: str) -> list:
    """ë°”ì´ì˜¤í… ì „ìš© ë‰´ìŠ¤ (BioSpace, FiercePharma)"""
    news = []

    # 1. BioSpace ê²€ìƒ‰
    try:
        url = f"https://www.biospace.com/search?q={ticker}"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, "html.parser")
            articles = soup.select("article h3 a, .article-title a")[:5]
            for a in articles:
                news.append({
                    "title": a.text.strip(),
                    "link": a.get("href", ""),
                    "source": "BioSpace"
                })
    except:
        pass

    # 2. êµ¬ê¸€ ë‰´ìŠ¤ ë°”ì´ì˜¤í… í‚¤ì›Œë“œ
    try:
        keywords = f"{ticker} FDA OR clinical OR trial OR Phase OR approval"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:5]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": "Google/FDA"
                })
    except:
        pass

    return news


def get_tech_news(ticker: str) -> list:
    """AI/Tech ì „ìš© ë‰´ìŠ¤"""
    news = []

    # êµ¬ê¸€ ë‰´ìŠ¤ AI/Tech í‚¤ì›Œë“œ
    try:
        keywords = f"{ticker} AI OR artificial intelligence OR GPU OR datacenter OR cloud"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:7]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": "Google/AI"
                })
    except:
        pass

    return news


def get_energy_news(ticker: str) -> list:
    """ì—ë„ˆì§€ ì „ìš© ë‰´ìŠ¤"""
    news = []

    try:
        keywords = f"{ticker} oil OR gas OR drilling OR OPEC OR energy"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:7]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": "Google/Energy"
                })
    except:
        pass

    return news


def get_automotive_news(ticker: str) -> list:
    """ìë™ì°¨/EV ì „ìš© ë‰´ìŠ¤"""
    news = []

    try:
        keywords = f"{ticker} EV OR electric vehicle OR battery OR autonomous OR Tesla OR charging"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:7]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": "Google/Auto"
                })
    except:
        pass

    return news


def get_retail_news(ticker: str) -> list:
    """ë¦¬í…Œì¼/ì´ì»¤ë¨¸ìŠ¤ ì „ìš© ë‰´ìŠ¤"""
    news = []

    try:
        keywords = f"{ticker} retail OR e-commerce OR consumer spending OR sales OR store"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:7]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": "Google/Retail"
                })
    except:
        pass

    return news


def get_consumer_news(ticker: str) -> list:
    """ì†Œë¹„ì¬/ì‹í’ˆ ì „ìš© ë‰´ìŠ¤"""
    news = []

    try:
        keywords = f"{ticker} food OR beverage OR consumer goods OR grocery OR brand"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:7]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": "Google/Consumer"
                })
    except:
        pass

    return news


def get_financial_news(ticker: str) -> list:
    """ê¸ˆìœµ/í•€í…Œí¬ ì „ìš© ë‰´ìŠ¤"""
    news = []

    try:
        keywords = f"{ticker} bank OR fintech OR interest rate OR Fed OR lending OR credit"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:7]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": "Google/Finance"
                })
    except:
        pass

    return news


def get_industrial_news(ticker: str) -> list:
    """ì‚°ì—…ì¬/ì œì¡° ì „ìš© ë‰´ìŠ¤"""
    news = []

    try:
        keywords = f"{ticker} manufacturing OR industrial OR defense OR aerospace OR contract"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:7]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": "Google/Industrial"
                })
    except:
        pass

    return news


def get_realestate_news(ticker: str) -> list:
    """ë¶€ë™ì‚°/ë¦¬ì¸  ì „ìš© ë‰´ìŠ¤"""
    news = []

    try:
        keywords = f"{ticker} REIT OR real estate OR property OR mortgage OR housing"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:7]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": "Google/RealEstate"
                })
    except:
        pass

    return news


def get_finviz_news(ticker: str) -> list:
    """Finviz ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘"""
    news = []

    try:
        url = f"https://finviz.com/quote.ashx?t={ticker}"
        resp = requests.get(url, headers=HEADERS, timeout=10)

        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, "html.parser")
            news_table = soup.find("table", {"id": "news-table"})

            if news_table:
                rows = news_table.find_all("tr")[:7]
                for row in rows:
                    link = row.find("a")
                    if link:
                        news.append({
                            "title": link.text.strip(),
                            "link": link.get("href", ""),
                            "source": "Finviz"
                        })
    except:
        pass

    return news


# ============================================================
# ë°”ì´ì˜¤í… íŠ¹í™” ë¶„ì„ (FDA, ì„ìƒì‹œí—˜)
# ============================================================

def get_biotech_catalysts(ticker: str, company_name: str) -> dict:
    """ë°”ì´ì˜¤í… ì´‰ë§¤ ë¶„ì„ (FDA, ì„ìƒì‹œí—˜)"""
    catalysts = {
        "fda_status": [],
        "clinical_trials": [],
        "pdufa_dates": [],
        "fast_track": False,
        "breakthrough": False,
        "orphan_drug": False,
    }

    # 1. FDA ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
    try:
        keywords = f"{ticker} FDA approval OR Fast Track OR PDUFA OR BLA OR NDA"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:5]:
            title = item.find("title")
            if title:
                title_lower = title.text.lower()

                # FDA ìƒíƒœ ê°ì§€
                if "fast track" in title_lower:
                    catalysts["fast_track"] = True
                if "breakthrough" in title_lower:
                    catalysts["breakthrough"] = True
                if "orphan" in title_lower:
                    catalysts["orphan_drug"] = True
                if "pdufa" in title_lower:
                    catalysts["pdufa_dates"].append(title.text)

                catalysts["fda_status"].append({
                    "headline": title.text,
                    "date": item.find("pubDate").text if item.find("pubDate") else ""
                })
    except:
        pass

    # 2. ClinicalTrials.gov API
    try:
        # íšŒì‚¬ëª… ì „ì²´ë¡œ ê²€ìƒ‰ (ë” ì •í™•)
        # "Greenwich LifeSciences" ì²˜ëŸ¼ ì• 2ë‹¨ì–´ ì‚¬ìš©
        if company_name:
            words = company_name.replace(",", "").replace(".", "").split()[:2]
            search_term = " ".join(words)
        else:
            search_term = ticker

        ct_url = f"https://clinicaltrials.gov/api/v2/studies?query.spons={search_term}&pageSize=10"
        resp = requests.get(ct_url, headers={"Accept": "application/json"}, timeout=15)

        if resp.status_code == 200:
            data = resp.json()
            studies = data.get("studies", [])

            for study in studies[:5]:
                protocol = study.get("protocolSection", {})
                id_module = protocol.get("identificationModule", {})
                status_module = protocol.get("statusModule", {})
                design_module = protocol.get("designModule", {})
                sponsor_module = protocol.get("sponsorCollaboratorsModule", {})

                # ìŠ¤í°ì„œ ì´ë¦„ í™•ì¸ (ì •í™•í•œ ë§¤ì¹­)
                lead_sponsor = sponsor_module.get("leadSponsor", {}).get("name", "")
                # íšŒì‚¬ëª…ì´ ìŠ¤í°ì„œì— í¬í•¨ë˜ì§€ ì•Šìœ¼ë©´ ìŠ¤í‚µ
                if company_name and company_name.split()[0].lower() not in lead_sponsor.lower():
                    continue

                phase_list = design_module.get("phases", [])
                phase = phase_list[0] if phase_list else "N/A"

                catalysts["clinical_trials"].append({
                    "nct_id": id_module.get("nctId", ""),
                    "title": id_module.get("briefTitle", "")[:80],
                    "phase": phase,
                    "status": status_module.get("overallStatus", ""),
                    "completion": status_module.get("primaryCompletionDateStruct", {}).get("date", "N/A"),
                    "sponsor": lead_sponsor[:40]
                })
    except Exception as e:
        pass

    return catalysts


def get_automotive_catalysts(ticker: str, company_name: str) -> dict:
    """ìë™ì°¨/EV ì´‰ë§¤ ë¶„ì„"""
    catalysts = {
        "production_numbers": [],
        "new_models": [],
        "ev_credits": False,
        "battery_partnership": False,
        "autonomous_update": False,
    }

    try:
        # EV/ìë™ì°¨ ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
        keywords = f"{ticker} production OR delivery OR new model OR EV tax credit OR battery"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:5]:
            title = item.find("title")
            if title:
                title_lower = title.text.lower()

                if "production" in title_lower or "deliver" in title_lower:
                    catalysts["production_numbers"].append(title.text)
                if "new model" in title_lower or "launch" in title_lower:
                    catalysts["new_models"].append(title.text)
                if "ev credit" in title_lower or "tax credit" in title_lower:
                    catalysts["ev_credits"] = True
                if "battery" in title_lower and "partner" in title_lower:
                    catalysts["battery_partnership"] = True
                if "autonomous" in title_lower or "self-driving" in title_lower:
                    catalysts["autonomous_update"] = True
    except:
        pass

    return catalysts


def get_retail_catalysts(ticker: str, company_name: str) -> dict:
    """ë¦¬í…Œì¼ ì´‰ë§¤ ë¶„ì„"""
    catalysts = {
        "same_store_sales": [],
        "ecommerce_growth": [],
        "holiday_sales": False,
        "store_openings": [],
        "inventory_update": False,
    }

    try:
        keywords = f"{ticker} same-store sales OR e-commerce OR holiday sales OR store opening"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:5]:
            title = item.find("title")
            if title:
                title_lower = title.text.lower()

                if "same-store" in title_lower or "comparable" in title_lower:
                    catalysts["same_store_sales"].append(title.text)
                if "e-commerce" in title_lower or "online sales" in title_lower:
                    catalysts["ecommerce_growth"].append(title.text)
                if "holiday" in title_lower or "black friday" in title_lower:
                    catalysts["holiday_sales"] = True
                if "open" in title_lower and "store" in title_lower:
                    catalysts["store_openings"].append(title.text)
                if "inventory" in title_lower:
                    catalysts["inventory_update"] = True
    except:
        pass

    return catalysts


def get_financial_catalysts(ticker: str, company_name: str) -> dict:
    """ê¸ˆìœµ ì´‰ë§¤ ë¶„ì„"""
    catalysts = {
        "fed_rate_impact": [],
        "loan_growth": [],
        "regulatory_news": [],
        "dividend_update": False,
        "capital_ratio": False,
    }

    try:
        keywords = f"{ticker} Fed rate OR interest rate OR loan growth OR regulation OR dividend"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:5]:
            title = item.find("title")
            if title:
                title_lower = title.text.lower()

                if "fed" in title_lower or "interest rate" in title_lower:
                    catalysts["fed_rate_impact"].append(title.text)
                if "loan" in title_lower and ("growth" in title_lower or "demand" in title_lower):
                    catalysts["loan_growth"].append(title.text)
                if "regulat" in title_lower or "compliance" in title_lower:
                    catalysts["regulatory_news"].append(title.text)
                if "dividend" in title_lower:
                    catalysts["dividend_update"] = True
                if "capital" in title_lower and "ratio" in title_lower:
                    catalysts["capital_ratio"] = True
    except:
        pass

    return catalysts


def get_industrial_catalysts(ticker: str, company_name: str) -> dict:
    """ì‚°ì—…ì¬ ì´‰ë§¤ ë¶„ì„"""
    catalysts = {
        "contracts": [],
        "gov_spending": [],
        "defense_budget": [],
        "supply_chain": False,
        "pmi_update": False,
    }

    try:
        keywords = f"{ticker} contract OR government OR defense budget OR supply chain OR manufacturing"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:5]:
            title = item.find("title")
            if title:
                title_lower = title.text.lower()

                if "contract" in title_lower and ("win" in title_lower or "award" in title_lower):
                    catalysts["contracts"].append(title.text)
                if "government" in title_lower and "spend" in title_lower:
                    catalysts["gov_spending"].append(title.text)
                if "defense" in title_lower and "budget" in title_lower:
                    catalysts["defense_budget"].append(title.text)
                if "supply chain" in title_lower:
                    catalysts["supply_chain"] = True
                if "pmi" in title_lower or "manufacturing index" in title_lower:
                    catalysts["pmi_update"] = True
    except:
        pass

    return catalysts


def get_realestate_catalysts(ticker: str, company_name: str) -> dict:
    """ë¶€ë™ì‚°/ë¦¬ì¸  ì´‰ë§¤ ë¶„ì„"""
    catalysts = {
        "rate_impact": [],
        "occupancy": [],
        "acquisitions": [],
        "cap_rate": False,
        "noi_growth": False,
    }

    try:
        keywords = f"{ticker} interest rate OR occupancy OR acquisition OR cap rate OR NOI"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:5]:
            title = item.find("title")
            if title:
                title_lower = title.text.lower()

                if "rate" in title_lower and ("cut" in title_lower or "hike" in title_lower):
                    catalysts["rate_impact"].append(title.text)
                if "occupancy" in title_lower:
                    catalysts["occupancy"].append(title.text)
                if "acqui" in title_lower or "purchase" in title_lower:
                    catalysts["acquisitions"].append(title.text)
                if "cap rate" in title_lower:
                    catalysts["cap_rate"] = True
                if "noi" in title_lower or "net operating" in title_lower:
                    catalysts["noi_growth"] = True
    except:
        pass

    return catalysts


# ============================================================
# 8-K ê³µì‹œ ë‚´ìš© íŒŒì‹±
# ============================================================

def parse_8k_content(ticker: str, cik: str) -> list:
    """ìµœê·¼ 8-K ê³µì‹œì—ì„œ ì£¼ìš” ì´ë²¤íŠ¸ ì¶”ì¶œ"""
    events = []
    headers = {"User-Agent": "DailyStockStory/1.0 (sean@example.com)"}

    if not cik:
        return events

    try:
        # ìµœê·¼ filing ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        filings_url = f"https://data.sec.gov/submissions/CIK{cik.zfill(10)}.json"
        resp = requests.get(filings_url, headers=headers, timeout=15)

        if resp.status_code == 200:
            data = resp.json()
            recent = data.get('filings', {}).get('recent', {})

            forms = recent.get('form', [])
            dates = recent.get('filingDate', [])
            accessions = recent.get('accessionNumber', [])
            descriptions = recent.get('primaryDocument', [])

            # ìµœê·¼ 8-Kë§Œ í•„í„°ë§ (ìµœëŒ€ 5ê°œ)
            eight_k_count = 0
            for i in range(min(50, len(forms))):
                if forms[i] == "8-K" and eight_k_count < 5:
                    eight_k_count += 1

                    # 8-K ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                    try:
                        acc = accessions[i].replace('-', '')
                        doc = descriptions[i] if i < len(descriptions) else ""
                        doc_url = f"https://www.sec.gov/Archives/edgar/data/{cik.lstrip('0')}/{acc}/{doc}"

                        doc_resp = requests.get(doc_url, headers=headers, timeout=15)

                        if doc_resp.status_code == 200:
                            text = doc_resp.text.lower()

                            # ì£¼ìš” ì´ë²¤íŠ¸ í‚¤ì›Œë“œ ê°ì§€
                            event_type = "ê¸°íƒ€"
                            importance = "ë³´í†µ"

                            if "fda" in text and ("approv" in text or "clear" in text):
                                event_type = "FDA ìŠ¹ì¸/í—ˆê°€"
                                importance = "ğŸ”¥ ì¤‘ìš”"
                            elif "phase" in text and ("result" in text or "data" in text):
                                event_type = "ì„ìƒ ê²°ê³¼ ë°œí‘œ"
                                importance = "ğŸ”¥ ì¤‘ìš”"
                            elif "agreement" in text or "partnership" in text or "collaborat" in text:
                                event_type = "ê³„ì•½/íŒŒíŠ¸ë„ˆì‹­"
                                importance = "âš¡ ì£¼ëª©"
                            elif "offering" in text or "securities" in text:
                                event_type = "ìœ ì¦/ê³µëª¨"
                                importance = "âš ï¸ í¬ì„"
                            elif "executive" in text or "officer" in text or "director" in text:
                                event_type = "ì„ì› ë³€ë™"
                                importance = "ë³´í†µ"
                            elif "earning" in text or "financial" in text or "quarter" in text:
                                event_type = "ì‹¤ì  ë°œí‘œ"
                                importance = "ğŸ“Š ì‹¤ì "

                            events.append({
                                "date": dates[i],
                                "type": event_type,
                                "importance": importance,
                                "accession": accessions[i]
                            })
                    except:
                        pass

    except:
        pass

    return events


# ============================================================
# 8. ìˆìŠ¤í€´ì¦ˆ ì ìˆ˜ ê³„ì‚° (v3 - Zero Borrow ë°˜ì˜)
# ============================================================

def calculate_squeeze_score_v3(data: dict, borrow: dict, in_regsho: bool, tech: dict) -> dict:
    """
    ìˆìŠ¤í€´ì¦ˆ ì ìˆ˜ v3 (0-100) - Zero Borrow ë°˜ì˜!

    í•µì‹¬: Zero Borrow = ìƒˆ ìˆ ì§„ì… ë¶ˆê°€ = ìŠ¤í€´ì¦ˆ ìµœì  ì¡°ê±´
    """
    score = 0
    details = []
    risks = []
    bullish = []

    # ========== ZERO BORROW (ìµœëŒ€ 30ì ) ==========
    if borrow.get("is_zero_borrow"):
        score += 30
        details.append("ğŸ”¥ ZERO BORROW (ë¹Œë¦´ ì£¼ì‹ ì—†ìŒ): +30ì ")
        bullish.append("ìƒˆ ìˆ ì§„ì… ë¶ˆê°€ëŠ¥ - ê¸°ì¡´ ìˆë§Œ ì»¤ë²„í•´ì•¼ í•¨")
    elif borrow.get("is_hard_to_borrow"):
        score += 15
        details.append("âš ï¸ Hard to Borrow: +15ì ")

    # ========== Borrow Rate (0-20ì ) ==========
    br = borrow.get("borrow_rate")
    if br and br < 999:  # 999ëŠ” Zero Borrow
        if br > 100:
            score += 20
            details.append(f"Borrow Rate {br:.1f}% (ê·¹ë‹¨ì ): +20ì ")
        elif br > 50:
            score += 15
            details.append(f"Borrow Rate {br:.1f}% (ë†’ìŒ): +15ì ")
        elif br > 20:
            score += 10
            details.append(f"Borrow Rate {br:.1f}%: +10ì ")

    # ========== Short Interest (0-20ì ) ==========
    si = data.get("short_pct_float")
    if si:
        si_pct = si * 100 if si < 1 else si
        if si_pct > 30:
            score += 20
            details.append(f"Short % of Float {si_pct:.1f}% (ë†’ìŒ): +20ì ")
        elif si_pct > 20:
            score += 15
            details.append(f"Short % of Float {si_pct:.1f}%: +15ì ")
        elif si_pct > 10:
            score += 10
            details.append(f"Short % of Float {si_pct:.1f}%: +10ì ")

    # ========== RegSHO (0-15ì ) ==========
    if in_regsho:
        score += 15
        details.append("RegSHO Threshold ë“±ì¬: +15ì ")
        bullish.append("FTD ë‹¤ìˆ˜ ë°œìƒ - ê°•ì œ ì»¤ë²„ë§ ì••ë ¥")

    # ========== Low Float (0-10ì ) ==========
    float_shares = data.get("float_shares")
    if float_shares:
        if float_shares < 5_000_000:
            score += 10
            details.append(f"ê·¹ì†Œí˜• Float ({fmt_num(float_shares)}): +10ì ")
            bullish.append("ì‘ì€ Float = ë§¤ìˆ˜ ì••ë ¥ì— ë¯¼ê°")
        elif float_shares < 10_000_000:
            score += 5
            details.append(f"Low Float ({fmt_num(float_shares)}): +5ì ")

    # ========== ëŒ€ì°¨ê°€ëŠ¥ ì£¼ì‹ (0-10ì ) ==========
    avail = borrow.get("available_shares")
    if avail is not None:
        if avail == 0:
            score += 10
            details.append("ëŒ€ì°¨ê°€ëŠ¥ ì£¼ì‹ 0: +10ì ")
        elif avail < 50000:
            score += 5
            details.append(f"ëŒ€ì°¨ê°€ëŠ¥ ë¶€ì¡± ({fmt_num(avail)}): +5ì ")

    # ========== ê±°ë˜ëŸ‰ ê¸‰ì¦ (0-5ì ) ==========
    vol_ratio = tech.get("vol_ratio", 1) if tech else 1
    if vol_ratio > 3:
        score += 5
        details.append(f"ê±°ë˜ëŸ‰ ê¸‰ì¦ {vol_ratio:.1f}x: +5ì ")
        bullish.append("ë†’ì€ ê´€ì‹¬ë„ & ìœ ë™ì„±")

    # ========== ë‚´ë¶€ì ë³´ìœ ìœ¨ (0-5ì ) ==========
    insider = data.get("insider_pct")
    if insider and insider > 0.3:
        score += 5
        details.append(f"ë‚´ë¶€ì ë³´ìœ  {insider*100:.1f}%: +5ì ")
        bullish.append("ë‚´ë¶€ì ë½ì—… = Float ì¶•ì†Œ íš¨ê³¼")

    # ========== ë¦¬ìŠ¤í¬ ë¶„ì„ ==========

    # RSI ê³¼ë§¤ìˆ˜
    rsi = tech.get("rsi") if tech else None
    if rsi:
        if rsi > 85:
            risks.append(f"ğŸ”´ RSI {rsi:.1f} - ê·¹ë‹¨ì  ê³¼ë§¤ìˆ˜, ê¸‰ë½ ìœ„í—˜")
        elif rsi > 70:
            risks.append(f"ğŸŸ¡ RSI {rsi:.1f} - ê³¼ë§¤ìˆ˜ êµ¬ê°„")

    # ë³¼ë¦°ì € ìƒë‹¨ ëŒíŒŒ
    bb_pos = tech.get("bb_position") if tech else None
    if bb_pos and bb_pos > 100:
        risks.append(f"ğŸŸ¡ ë³¼ë¦°ì € ìƒë‹¨ ëŒíŒŒ ({bb_pos:.1f}%) - ê³¼ì—´")

    # ATR ë³€ë™ì„±
    atr_pct = tech.get("atr_pct") if tech else None
    if atr_pct and atr_pct > 15:
        risks.append(f"ğŸŸ¡ ê·¹ë‹¨ì  ë³€ë™ì„± (ATR {atr_pct:.1f}%)")

    # Short ë³€í™” (ê°ì†Œ = ì»¤ë²„ë§ ì§„í–‰ì¤‘)
    curr = data.get("shares_short")
    prev = data.get("shares_short_prior")
    if curr and prev and prev > 0:
        change = ((curr - prev) / prev) * 100
        if change < -30:
            risks.append(f"âš ï¸ Short Interest {change:.1f}% ê¸‰ê° - ì»¤ë²„ë§ ë§ˆë¬´ë¦¬ ë‹¨ê³„?")

    return {
        "score": min(round(score, 1), 100),
        "details": details,
        "risks": risks,
        "bullish": bullish
    }


# ============================================================
# 9. Gemini AI ë¶„ì„
# ============================================================

def analyze_with_gemini(ticker: str, data: dict, borrow: dict, tech: dict,
                        in_regsho: bool, score_info: dict, news: list,
                        force_normal: bool = False, sec_info: dict = None,
                        sec_filings: dict = None) -> str:
    """Gemini AIë¡œ ì¢…í•© ë¶„ì„"""
    sec_info = sec_info or {}
    sec_filings = sec_filings or {}

    # ë°ì´í„° ìš”ì•½ ìƒì„±
    # ì•ˆì „í•œ ê°’ ì¶”ì¶œ
    rsi_val = f"{tech.get('rsi'):.1f}" if tech.get('rsi') else 'N/A'
    bb_val = f"{tech.get('bb_position'):.1f}" if tech.get('bb_position') else 'N/A'
    vol_val = f"{tech.get('vol_ratio'):.2f}" if tech.get('vol_ratio') else 'N/A'

    # ì¬ë¬´ ì§€í‘œ ì¶”ì¶œ
    eps = data.get('eps', 0) or 0
    pe = data.get('pe_ratio')
    debt_equity = data.get('debt_to_equity')
    cash = data.get('total_cash', 0) or 0
    debt = data.get('total_debt', 0) or 0
    revenue = data.get('revenue', 0) or 0
    net_income = data.get('net_income', 0) or 0

    summary = f"""
## {ticker} ({data.get('name', ticker)}) ë¶„ì„ ë°ì´í„°

### ê¸°ë³¸ ì •ë³´
- í˜„ì¬ê°€: ${data.get('price', 'N/A')}
- ì• í”„í„°ë§ˆì¼“: ${data.get('post_market', 'N/A')}
- ì‹œê°€ì´ì•¡: {fmt_num(data.get('market_cap'), '$')}
- Float: {fmt_num(data.get('float_shares'))}
- ì„¹í„°: {data.get('sector', 'N/A')}
- ì§ì›ìˆ˜: {data.get('employees', 'N/A')}ëª…

### ì¬ë¬´ ìƒíƒœ (ì¤‘ìš”!)
- EPS: ${eps:.2f}
- P/E: {pe if pe else 'N/A (ì ì)'}
- ë§¤ì¶œ: {fmt_num(revenue, '$')}
- ìˆœì´ìµ: {fmt_num(net_income, '$')}
- ì´ í˜„ê¸ˆ: {fmt_num(cash, '$')}
- ì´ ë¶€ì±„: {fmt_num(debt, '$')}
- ë¶€ì±„ë¹„ìœ¨(D/E): {debt_equity if debt_equity else 'N/A'}

### ìˆ í¬ì§€ì…˜
- Short % of Float: {fmt_pct(data.get('short_pct_float'))}
- Short Shares: {fmt_num(data.get('shares_short'))}
- Days to Cover: {data.get('short_ratio', 'N/A')}
- Zero Borrow: {'âœ… YES (ë¹Œë¦´ ì£¼ì‹ ì—†ìŒ!)' if borrow.get('is_zero_borrow') else 'âŒ NO'}
- Borrow Rate: {borrow.get('borrow_rate', 'N/A')}%
- RegSHO ë“±ì¬: {'âœ… YES' if in_regsho else 'âŒ NO'}

### ê¸°ìˆ ì  ì§€í‘œ
- RSI: {rsi_val}
- ë³¼ë¦°ì € ìœ„ì¹˜: {bb_val}%
- ê±°ë˜ëŸ‰ ë¹„ìœ¨: {vol_val}x
- 1ì¼ ë³€í™”: {tech.get('change_1d', 0):.2f}%
- 5ì¼ ë³€í™”: {tech.get('change_5d', 0):.2f}%
- 20ì¼ ë³€í™”: {tech.get('change_20d', 0):.2f}%

### ìˆìŠ¤í€´ì¦ˆ ì ìˆ˜
- ì ìˆ˜: {score_info.get('score', 0)}/100
- ì£¼ìš” ìš”ì†Œ: {', '.join(score_info.get('details', [])[:3])}
- ë¦¬ìŠ¤í¬: {', '.join(score_info.get('risks', [])[:3]) if score_info.get('risks') else 'ì—†ìŒ'}

### ìµœê·¼ ë‰´ìŠ¤
{chr(10).join([f"- {n.get('title', 'N/A')}" for n in news[:3]]) if news else 'ë‰´ìŠ¤ ì—†ìŒ'}

### SEC ê³µì‹œ ë¶„ì„ (í¬ì„/ë¹š/Covenant)
- Warrant ì–¸ê¸‰: {sec_info.get('warrant_mentions', 0)}ê±´ {'âš ï¸ í¬ì„ ìœ„í—˜!' if sec_info.get('has_warrant_risk') else 'âœ… OK'}
- Dilution ì–¸ê¸‰: {sec_info.get('dilution_mentions', 0)}ê±´ {'âš ï¸ í¬ì„ ìœ„í—˜!' if sec_info.get('dilution_risk') else 'âœ… OK'}
- Covenant/ë¹š ì¡°í•­: {sec_info.get('covenant_mentions', 0)}ê±´ {'âš ï¸ ë¹š ìˆìŒ!' if sec_info.get('has_debt_covenant') else 'âœ… OK'}
- Debt ì–¸ê¸‰: {sec_info.get('debt_mentions', 0)}ê±´
- Lock-up ì–¸ê¸‰: {sec_info.get('lockup_mentions', 0)}ê±´ {'ğŸ”’ ë‚´ë¶€ì ë§¤ë„ ì œí•œ' if sec_info.get('has_lockup') else ''}
- S-3/424B ì˜¤í¼ë§: {sec_info.get('offering_mentions', 0)}ê±´ {'âš ï¸ ì˜¤í¼ë§ ìœ„í—˜!' if sec_info.get('has_offering_risk') else 'âœ… OK'}
- í˜¸ì¬ ê³µì‹œ: {sec_info.get('positive_news', 0)}ê±´ {'ğŸ”¥' if sec_info.get('has_positive_news') else ''}
- ì•…ì¬ ê³µì‹œ: {sec_info.get('negative_news', 0)}ê±´ {'âŒ' if sec_info.get('has_negative_news') else ''}

### SPAC/Earnout ì •ë³´
- SPAC ì—¬ë¶€: {'ğŸš€ SPAC í•©ë³‘ ì¢…ëª©!' if sec_filings and sec_filings.get('is_spac') else 'âŒ ì•„ë‹˜'}
- ë‚´ë¶€ì ë½ì—… ê°€ê²©: {sec_filings.get('insider_lockup_price', 'ì •ë³´ì—†ìŒ') if sec_filings else 'ì •ë³´ì—†ìŒ'}
- Earnout ì¡°ê±´ ê°€ê²©: {', '.join(sec_filings.get('earnout_prices', [])) if sec_filings and sec_filings.get('earnout_prices') else 'ì •ë³´ì—†ìŒ'}
- Earnout ì£¼ì‹ ìˆ˜: {sec_filings.get('earnout_shares', 'ì •ë³´ì—†ìŒ') if sec_filings else 'ì •ë³´ì—†ìŒ'}
"""

    # ìˆìŠ¤í€´ì¦ˆ ìƒí™©ì¸ì§€ íŒë‹¨ (force_normalì´ë©´ ë¬´ì¡°ê±´ ì¼ë°˜ ë¶„ì„)
    is_squeeze_play = False if force_normal else (
        borrow.get('is_zero_borrow') or (data.get('short_pct_float') and data.get('short_pct_float') > 0.2)
    )

    if is_squeeze_play:
        prompt = f"""
ë„ˆëŠ” ìˆìŠ¤í€´ì¦ˆ ì „ë¬¸ íŠ¸ë ˆì´ë”ì•¼. í•µì‹¬ë§Œ ë¶„ì„í•´ì¤˜.

{summary}

âš ï¸ ì¤‘ìš”: ì´ê±´ **ìˆìŠ¤í€´ì¦ˆ í”Œë ˆì´**ì•¼! í€ë”ë©˜í„¸ ë¶„ì„ì€ ì˜ë¯¸ì—†ì–´.
ìˆìŠ¤í€´ì¦ˆëŠ” ìˆ˜ê¸‰ ì‹¸ì›€ì´ì•¼. í€ë”ë©˜í„¸ ì•ˆì¢‹ì•„ë„ ìˆë“¤ì´ ê°•ì œë¡œ ì‚¬ì•¼í•˜ë©´ í­ë“±í•´.

ë‹¤ìŒì„ ë¶„ì„í•´ì¤˜:

## 1. ìˆ˜ê¸‰ ë¶„ì„ (ê°€ì¥ ì¤‘ìš”!)
- Zero Borrow ìƒíƒœë©´: ìˆë“¤ì´ **ìƒˆë¡œ ëª» ë“¤ì–´ì˜¤ê³ , ë‚˜ê°€ë ¤ë©´ ì‹œì¥ì—ì„œ ì‚¬ì•¼í•¨**
- Short % of Float 29%ë©´: Floatì˜ ê±°ì˜ 1/3ì´ ìˆí¬ì§€ì…˜
- Float 296ë§Œì£¼ë©´: ê·¹ì†Œí˜•, ë§¤ìˆ˜ ì••ë ¥ì— ë¯¼ê°
- ì´ ìˆ˜ê¸‰ êµ¬ì¡°ì—ì„œ **ìˆë“¤ì´ ê°•ì œì²­ì‚°í•˜ë©´ ì–´ë–»ê²Œ ë˜ëƒ?**

## 2. ëª¨ë©˜í…€ ë¶„ì„
- ì• í”„í„° +255% ê°­ì—…ì´ë©´: ë‚´ì¼ ì¥ì‹œì‘ ë•Œ **FOMO** í­ë°œ
- í•´ì™¸ íˆ¬ììë“¤ ë°˜ì‘ ì˜ˆìƒ
- RSI 88ì´ë¼ë„ ìˆìŠ¤í€´ì¦ˆì—ì„  100 ë„˜ê²Œ ê°€ê¸°ë„ í•¨

## 3. íƒ€ì´ë° ë¶„ì„
- ì§€ê¸ˆì´ **ì´ˆì…**ì´ëƒ, **ì¤‘ë°˜**ì´ëƒ, **ëë¬¼**ì´ëƒ?
- Days to Cover 0.16ì¼ì´ë©´ ë¹¨ë¦¬ ì²­ì‚°ëœë‹¤ëŠ” ëœ»
- ê·¼ë° Zero Borrowë©´ ë¹Œë¦´ ì£¼ì‹ì´ ì—†ì–´ì„œ ëª» ë¹ ì§

## 4. ì „ëµ (ìˆìŠ¤í€´ì¦ˆ ê¸°ì¤€!)
- ì‹ ê·œ ì§„ì…: ì–¸ì œ ë“¤ì–´ê°€ë©´ ì¢‹ëƒ, ìœ„í—˜í•˜ëƒ
- í™€ë”© ì¤‘ì´ë©´: ì–¸ì œê¹Œì§€ ë“¤ê³ ê°ˆë§Œ í•˜ëƒ
- ëª©í‘œê°€: ìˆì»¤ë²„ë§ ì™„ë£Œ ì‹œ ì˜ˆìƒ ê°€ê²©ëŒ€
- ì†ì ˆê°€: ìŠ¤í€´ì¦ˆ ì‹¤íŒ¨ ì‹œ íƒˆì¶œ ë¼ì¸

## 5. í€ë”ë©˜í„¸ (ì°¸ê³ ìš©)
- íšŒì‚¬ ìƒíƒœê°€ ì–´ë–¤ì§€ ê°„ë‹¨íˆ
- ê·¼ë° ìˆìŠ¤í€´ì¦ˆì—” í€ë”ë©˜í„¸ ì˜ë¯¸ì—†ë‹¤ëŠ” ê²ƒë„ ì–¸ê¸‰

í•µì‹¬: ìˆìŠ¤í€´ì¦ˆëŠ” **ìˆ˜ê¸‰ ê²Œì„**ì´ì•¼.
í€ë”ë©˜í„¸ ì•ˆì¢‹ì•„ë„ ìˆë“¤ì´ ì²­ì‚°í•´ì•¼í•˜ë©´ ê°€ê²©ì€ í­ë“±í•´.
GME, AMC ë‹¤ ê·¸ë¬ì–ì•„.
"""
    else:
        prompt = f"""
ë„ˆëŠ” ì£¼ì‹ ë¶„ì„ê°€ì•¼. ì´ ì¢…ëª© íˆ¬ìí• ë§Œí•œì§€ ë¶„ì„í•´ì¤˜.

{summary}

ë‹¤ìŒì„ ë¶„ì„í•´ì¤˜:

## 1. í€ë”ë©˜í„¸ ë¶„ì„
- ì´ íšŒì‚¬ê°€ ëˆì„ ë²„ëŠ” íšŒì‚¬ì¸ì§€
- ë§¤ì¶œ, ì´ìµ, ì„±ì¥ì„±
- ë¶€ì±„ ìƒíƒœ, í˜„ê¸ˆ ë³´ìœ 
- ë°¸ë¥˜ì—ì´ì…˜ì´ ì ì •í•œì§€

## 2. ê¸°ìˆ ì  ë¶„ì„
- í˜„ì¬ ì¶”ì„¸
- RSI, ë³¼ë¦°ì €ë°´ë“œ ìƒíƒœ
- ì§€ì§€ì„ /ì €í•­ì„ 

## 3. ë¦¬ìŠ¤í¬ ìš”ì¸
- ì–´ë–¤ ìœ„í—˜ì´ ìˆëŠ”ì§€
- ê¸‰ë½ ê°€ëŠ¥ì„±

## 4. íˆ¬ì ì˜ê²¬
- ë§¤ìˆ˜/í™€ë“œ/ë§¤ë„ ì¤‘ ë­ê°€ ë§ëŠ”ì§€
- ëª©í‘œê°€, ì†ì ˆê°€
- íˆ¬ì ì‹œ ì£¼ì˜ì 

êµ¬ì²´ì ì¸ ìˆ«ìì™€ ê·¼ê±°ë¥¼ ë“¤ì–´ì„œ ë¶„ì„í•´ì¤˜.
"""

    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.0-flash',
            contents={'text': prompt},
        )
        return response.text
    except Exception as e:
        return f"âš ï¸ Gemini ë¶„ì„ ì‹¤íŒ¨: {e}"


# ============================================================
# 10. ì¶œë ¥ í•¨ìˆ˜ë“¤
# ============================================================

def print_basic_info(data: dict):
    """ê¸°ë³¸ ì •ë³´ ì¶œë ¥"""
    section("íšŒì‚¬ ê°œìš”", "ğŸ¢")

    print(f"  íšŒì‚¬ëª…: {data['name']}")
    print(f"  ì„¹í„°: {data['sector'] or 'N/A'} / {data['industry'] or 'N/A'}")
    print(f"  ì§ì›ìˆ˜: {fmt_num(data['employees'])}ëª…")
    print(f"  ì›¹ì‚¬ì´íŠ¸: {data['website'] or 'N/A'}")


def print_price_info(data: dict):
    """ê°€ê²© ì •ë³´"""
    section("ê°€ê²© ì •ë³´", "ğŸ’°")

    price = data['price']
    prev = data['prev_close']
    change = ((price / prev) - 1) * 100 if price and prev else 0
    emoji = "ğŸŸ¢" if change > 0 else "ğŸ”´" if change < 0 else "âšª"

    print(f"  í˜„ì¬ê°€: ${price:.2f} {emoji} {change:+.2f}%" if price else "  í˜„ì¬ê°€: N/A")

    if data.get('pre_market'):
        pm_change = ((data['pre_market'] / price) - 1) * 100 if price else 0
        print(f"  í”„ë¦¬ë§ˆì¼“: ${data['pre_market']:.2f} ({pm_change:+.2f}%)")

    if data.get('post_market'):
        am_change = ((data['post_market'] / price) - 1) * 100 if price else 0
        print(f"  ì• í”„í„°ë§ˆì¼“: ${data['post_market']:.2f} ({am_change:+.2f}%) ğŸ”¥")

    print(f"\n  52ì£¼: ${data['52w_low']:.2f} ~ ${data['52w_high']:.2f}" if data['52w_low'] else "")
    print(f"  ì‹œê°€ì´ì•¡: {fmt_num(data['market_cap'], '$')}")
    print(f"  Float: {fmt_num(data['float_shares'])}")


def print_short_data(data: dict, borrow: dict, in_regsho: bool):
    """ìˆ ë°ì´í„°"""
    section("ìˆ í¬ì§€ì…˜ ë¶„ì„", "ğŸ©³")

    # Zero Borrow ê°•ì¡°!
    if borrow.get("is_zero_borrow"):
        print(f"\n  {'ğŸ”¥'*10}")
        print(f"  ğŸš¨ ZERO BORROW! ë¹Œë¦´ ì£¼ì‹ ì—†ìŒ! ğŸš¨")
        print(f"  â†’ ìƒˆë¡œìš´ ìˆ í¬ì§€ì…˜ ì§„ì… ë¶ˆê°€ëŠ¥")
        print(f"  â†’ ê¸°ì¡´ ìˆì€ ì‹œì¥ì—ì„œ ì‚¬ì•¼ë§Œ íƒˆì¶œ ê°€ëŠ¥")
        print(f"  {'ğŸ”¥'*10}\n")
    elif borrow.get("is_hard_to_borrow"):
        print(f"\n  âš ï¸ HARD TO BORROW - ëŒ€ì°¨ ì–´ë ¤ì›€\n")

    si_pct = data['short_pct_float']
    print(f"  Short % of Float: {fmt_pct(si_pct)}")
    print(f"  Short Shares: {fmt_num(data['shares_short'])}")
    print(f"  Days to Cover: {data['short_ratio']:.2f}ì¼" if data['short_ratio'] else "")

    # Short ë³€í™”
    curr = data['shares_short']
    prev = data['shares_short_prior']
    if curr and prev:
        change = ((curr - prev) / prev) * 100
        emoji = "ğŸ“ˆ ì¦ê°€" if change > 0 else "ğŸ“‰ ê°ì†Œ"
        print(f"  Short ë³€í™”: {emoji} {change:+.1f}%")

    subsection("Borrow Rate")
    br = borrow.get('borrow_rate')
    if br == 999:
        print(f"  Borrow Rate: âˆ (Zero Borrow)")
    elif br:
        print(f"  Borrow Rate: {br:.1f}%")
    else:
        print(f"  Borrow Rate: N/A")

    print(f"  ëŒ€ì°¨ê°€ëŠ¥ ì£¼ì‹: {fmt_num(borrow.get('available_shares'))}")

    subsection("RegSHO Threshold")
    if in_regsho:
        print(f"  âœ… ë“±ì¬ë¨ - FTD ë‹¤ìˆ˜ ë°œìƒ, ê°•ì œ ì»¤ë²„ë§ ì••ë ¥")
    else:
        print(f"  âŒ ë¯¸ë“±ì¬")


def print_technicals(tech: dict, price: float):
    """ê¸°ìˆ ì  ì§€í‘œ"""
    section("ê¸°ìˆ ì  ë¶„ì„", "ğŸ“ˆ")

    if not tech:
        print("  ë°ì´í„° ì—†ìŒ")
        return

    rsi = tech.get('rsi')
    if rsi:
        status = "ğŸ”´ ê·¹ë‹¨ì  ê³¼ë§¤ìˆ˜" if rsi > 80 else "ğŸŸ  ê³¼ë§¤ìˆ˜" if rsi > 70 else "ğŸŸ¢ ê³¼ë§¤ë„" if rsi < 30 else "âšª ì¤‘ë¦½"
        print(f"  RSI(14): {rsi:.2f} {status}")

    macd_hist = tech.get('macd_hist')
    if macd_hist is not None:
        trend = "ğŸ“ˆ ìƒìŠ¹" if macd_hist > 0 else "ğŸ“‰ í•˜ë½"
        print(f"  MACD Histogram: {macd_hist:.4f} {trend}")

    bb_pos = tech.get('bb_position')
    if bb_pos is not None:
        status = "ğŸ”´ ìƒë‹¨ ëŒíŒŒ" if bb_pos > 100 else "ğŸŸ¢ í•˜ë‹¨ ì´íƒˆ" if bb_pos < 0 else ""
        print(f"  ë³¼ë¦°ì € ìœ„ì¹˜: {bb_pos:.1f}% {status}")

    vol_ratio = tech.get('vol_ratio', 1)
    vol_status = "ğŸ”¥ğŸ”¥ğŸ”¥" if vol_ratio > 5 else "ğŸ”¥" if vol_ratio > 2 else ""
    print(f"  ê±°ë˜ëŸ‰ ë¹„ìœ¨: {vol_ratio:.2f}x {vol_status}")

    atr_pct = tech.get('atr_pct')
    if atr_pct:
        print(f"  ë³€ë™ì„±(ATR%): {atr_pct:.2f}%")

    subsection("ê°€ê²© ë³€í™”")
    print(f"  1ì¼: {tech.get('change_1d', 0):+.2f}%")
    print(f"  5ì¼: {tech.get('change_5d', 0):+.2f}%")
    print(f"  20ì¼: {tech.get('change_20d', 0):+.2f}%")


def print_squeeze_score(score_info: dict):
    """ìŠ¤í€´ì¦ˆ ì ìˆ˜"""
    section("ìˆìŠ¤í€´ì¦ˆ ì¢…í•© ì ìˆ˜", "ğŸ°")

    score = score_info['score']

    if score >= 80:
        grade = "ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ ê·¹ë‹¨ì  (ìˆ ì§€ì˜¥)"
    elif score >= 60:
        grade = "ğŸ”¥ğŸ”¥ğŸ”¥ ë§¤ìš° ë†’ìŒ"
    elif score >= 40:
        grade = "ğŸ”¥ğŸ”¥ ë†’ìŒ"
    elif score >= 20:
        grade = "ğŸ”¥ ë³´í†µ"
    else:
        grade = "â„ï¸ ë‚®ìŒ"

    bar_filled = int(score / 5)
    bar = "â–ˆ" * bar_filled + "â–‘" * (20 - bar_filled)
    print(f"\n  [{bar}] {score}/100")
    print(f"  ë“±ê¸‰: {grade}")

    if score_info.get('details'):
        subsection("ì ìˆ˜ êµ¬ì„±")
        for detail in score_info['details']:
            print(f"    â€¢ {detail}")

    if score_info.get('bullish'):
        subsection("ğŸŸ¢ ê°•ì„¸ ìš”ì¸")
        for b in score_info['bullish']:
            print(f"    âœ… {b}")

    if score_info.get('risks'):
        subsection("ğŸ”´ ë¦¬ìŠ¤í¬ ìš”ì¸")
        for risk in score_info['risks']:
            print(f"    {risk}")


def print_officers(officers: list):
    """ê²½ì˜ì§„"""
    section("ê²½ì˜ì§„", "ğŸ‘”")

    if not officers:
        print("  ì •ë³´ ì—†ìŒ")
        return

    for i, o in enumerate(officers[:5], 1):
        name = o.get("name", "N/A")
        title = o.get("title", "N/A")
        age = o.get("age")
        pay = o.get("totalPay")

        print(f"\n  [{i}] {name}")
        print(f"      {title}")
        if age:
            print(f"      ë‚˜ì´: {age}ì„¸")
        if pay:
            print(f"      ë³´ìˆ˜: {fmt_num(pay, '$')}")


def print_news(news: list):
    """ë‰´ìŠ¤"""
    section("ìµœê·¼ ë‰´ìŠ¤", "ğŸ“°")

    if not news:
        print("  ë‰´ìŠ¤ ì—†ìŒ")
        return

    for i, n in enumerate(news[:5], 1):
        title = n.get('title', 'N/A')
        publisher = n.get('publisher', '')
        print(f"\n  [{i}] {title}")
        if publisher:
            print(f"      ì¶œì²˜: {publisher}")


def print_sector_news(sector_news: dict):
    """ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤ ì¶œë ¥"""
    source = sector_news.get("source", "General")
    section(f"ì„¹í„°ë³„ ë‰´ìŠ¤ ({source})", "ğŸ“¡")

    # ì„¹í„° íŠ¹í™” ë‰´ìŠ¤
    specific = sector_news.get("sector_specific", [])
    if specific:
        subsection(f"{source} ì „ë¬¸ ë‰´ìŠ¤ (ìµœê·¼ 60ì¼)")
        for i, n in enumerate(specific[:5], 1):
            title = n.get('title', 'N/A')[:70]
            src = n.get('source', '')
            print(f"  [{i}] {title}...")
            if src:
                print(f"      ğŸ“Œ {src}")
    else:
        print("  ì„¹í„° íŠ¹í™” ë‰´ìŠ¤ ì—†ìŒ")

    # ì¼ë°˜ ë‰´ìŠ¤ (ë°±ì—…)
    general = sector_news.get("general_news", [])
    if general:
        subsection("ì¼ë°˜ ë‰´ìŠ¤ (Google)")
        for i, n in enumerate(general[:3], 1):
            title = n.get('title', 'N/A')[:70]
            print(f"  [{i}] {title}...")


def print_biotech_catalysts(catalysts: dict):
    """ë°”ì´ì˜¤í… ì´‰ë§¤ ì¶œë ¥"""
    section("ë°”ì´ì˜¤í… ì´‰ë§¤ ë¶„ì„", "ğŸ’Š")

    # FDA ìƒíƒœ
    if catalysts.get("fast_track"):
        print("  ğŸš€ FDA Fast Track ì§€ì •!")
    if catalysts.get("breakthrough"):
        print("  â­ FDA Breakthrough ì§€ì •!")
    if catalysts.get("orphan_drug"):
        print("  ğŸ¥ Orphan Drug ì§€ì •!")

    # FDA ê´€ë ¨ ë‰´ìŠ¤
    fda_status = catalysts.get("fda_status", [])
    if fda_status:
        subsection("FDA ê´€ë ¨ ë‰´ìŠ¤")
        for i, news in enumerate(fda_status[:3], 1):
            headline = news.get('headline', '')[:70]
            print(f"  [{i}] {headline}...")

    # ì„ìƒì‹œí—˜ ì •ë³´
    trials = catalysts.get("clinical_trials", [])
    if trials:
        subsection("ì§„í–‰ ì¤‘ì¸ ì„ìƒì‹œí—˜ (ClinicalTrials.gov)")
        for trial in trials[:3]:
            nct = trial.get('nct_id', '')
            title = trial.get('title', '')[:60]
            phase = trial.get('phase', 'N/A')
            status = trial.get('status', '')
            completion = trial.get('completion', 'N/A')
            sponsor = trial.get('sponsor', '')

            status_emoji = "ğŸŸ¢" if status == "RECRUITING" else "ğŸŸ¡" if "ACTIVE" in status.upper() else "âšª"
            print(f"  {status_emoji} [{phase}] {title}...")
            print(f"      NCT: {nct} | ì™„ë£Œì˜ˆì •: {completion}")
            if sponsor:
                print(f"      ìŠ¤í°ì„œ: {sponsor}")
    else:
        print("  ì„ìƒì‹œí—˜ ì •ë³´ ì—†ìŒ (ë˜ëŠ” ê²€ìƒ‰ ì‹¤íŒ¨)")


def print_automotive_catalysts(catalysts: dict):
    """ìë™ì°¨/EV ì´‰ë§¤ ì¶œë ¥"""
    section("ìë™ì°¨/EV ì´‰ë§¤ ë¶„ì„", "ğŸš—")

    if catalysts.get("ev_credits"):
        print("  âš¡ EV ì„¸ì•¡ê³µì œ ê´€ë ¨ ë‰´ìŠ¤!")
    if catalysts.get("battery_partnership"):
        print("  ğŸ”‹ ë°°í„°ë¦¬ íŒŒíŠ¸ë„ˆì‹­ ë‰´ìŠ¤!")
    if catalysts.get("autonomous_update"):
        print("  ğŸ¤– ììœ¨ì£¼í–‰ ì—…ë°ì´íŠ¸!")

    production = catalysts.get("production_numbers", [])
    if production:
        subsection("ìƒì‚°/ë°°ì†¡ ë‰´ìŠ¤")
        for i, news in enumerate(production[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    models = catalysts.get("new_models", [])
    if models:
        subsection("ì‹ ëª¨ë¸ ì¶œì‹œ")
        for i, news in enumerate(models[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    if not production and not models:
        print("  ìµœê·¼ ìë™ì°¨ ê´€ë ¨ ì´‰ë§¤ ì—†ìŒ")


def print_retail_catalysts(catalysts: dict):
    """ë¦¬í…Œì¼ ì´‰ë§¤ ì¶œë ¥"""
    section("ë¦¬í…Œì¼ ì´‰ë§¤ ë¶„ì„", "ğŸ›’")

    if catalysts.get("holiday_sales"):
        print("  ğŸ„ ì—°ë§ ì‡¼í•‘ ì‹œì¦Œ ë‰´ìŠ¤!")
    if catalysts.get("inventory_update"):
        print("  ğŸ“¦ ì¬ê³  ê´€ë ¨ ì—…ë°ì´íŠ¸!")

    sss = catalysts.get("same_store_sales", [])
    if sss:
        subsection("ë™ì¼ì í¬ ë§¤ì¶œ")
        for i, news in enumerate(sss[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    ecom = catalysts.get("ecommerce_growth", [])
    if ecom:
        subsection("ì´ì»¤ë¨¸ìŠ¤ ì„±ì¥")
        for i, news in enumerate(ecom[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    stores = catalysts.get("store_openings", [])
    if stores:
        subsection("ë§¤ì¥ ì˜¤í”ˆ/íì‡„")
        for i, news in enumerate(stores[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    if not sss and not ecom and not stores:
        print("  ìµœê·¼ ë¦¬í…Œì¼ ê´€ë ¨ ì´‰ë§¤ ì—†ìŒ")


def print_financial_catalysts(catalysts: dict):
    """ê¸ˆìœµ ì´‰ë§¤ ì¶œë ¥"""
    section("ê¸ˆìœµ ì´‰ë§¤ ë¶„ì„", "ğŸ¦")

    if catalysts.get("dividend_update"):
        print("  ğŸ’° ë°°ë‹¹ ê´€ë ¨ ë‰´ìŠ¤!")
    if catalysts.get("capital_ratio"):
        print("  ğŸ“Š ìë³¸ë¹„ìœ¨ ê´€ë ¨ ë‰´ìŠ¤!")

    fed = catalysts.get("fed_rate_impact", [])
    if fed:
        subsection("ê¸ˆë¦¬ ì˜í–¥")
        for i, news in enumerate(fed[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    loan = catalysts.get("loan_growth", [])
    if loan:
        subsection("ëŒ€ì¶œ ì„±ì¥")
        for i, news in enumerate(loan[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    reg = catalysts.get("regulatory_news", [])
    if reg:
        subsection("ê·œì œ ë‰´ìŠ¤")
        for i, news in enumerate(reg[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    if not fed and not loan and not reg:
        print("  ìµœê·¼ ê¸ˆìœµ ê´€ë ¨ ì´‰ë§¤ ì—†ìŒ")


def print_industrial_catalysts(catalysts: dict):
    """ì‚°ì—…ì¬ ì´‰ë§¤ ì¶œë ¥"""
    section("ì‚°ì—…ì¬ ì´‰ë§¤ ë¶„ì„", "ğŸ­")

    if catalysts.get("supply_chain"):
        print("  ğŸšš ê³µê¸‰ë§ ê´€ë ¨ ë‰´ìŠ¤!")
    if catalysts.get("pmi_update"):
        print("  ğŸ“ˆ PMI/ì œì¡°ì—… ì§€ìˆ˜ ë‰´ìŠ¤!")

    contracts = catalysts.get("contracts", [])
    if contracts:
        subsection("ìˆ˜ì£¼/ê³„ì•½")
        for i, news in enumerate(contracts[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    gov = catalysts.get("gov_spending", [])
    if gov:
        subsection("ì •ë¶€ ì§€ì¶œ")
        for i, news in enumerate(gov[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    defense = catalysts.get("defense_budget", [])
    if defense:
        subsection("êµ­ë°© ì˜ˆì‚°")
        for i, news in enumerate(defense[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    if not contracts and not gov and not defense:
        print("  ìµœê·¼ ì‚°ì—…ì¬ ê´€ë ¨ ì´‰ë§¤ ì—†ìŒ")


def print_realestate_catalysts(catalysts: dict):
    """ë¶€ë™ì‚°/ë¦¬ì¸  ì´‰ë§¤ ì¶œë ¥"""
    section("ë¶€ë™ì‚°/ë¦¬ì¸  ì´‰ë§¤ ë¶„ì„", "ğŸ ")

    if catalysts.get("cap_rate"):
        print("  ğŸ“‰ Cap Rate ê´€ë ¨ ë‰´ìŠ¤!")
    if catalysts.get("noi_growth"):
        print("  ğŸ“ˆ NOI ì„±ì¥ ê´€ë ¨ ë‰´ìŠ¤!")

    rate = catalysts.get("rate_impact", [])
    if rate:
        subsection("ê¸ˆë¦¬ ì˜í–¥")
        for i, news in enumerate(rate[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    occ = catalysts.get("occupancy", [])
    if occ:
        subsection("ì ìœ ìœ¨")
        for i, news in enumerate(occ[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    acq = catalysts.get("acquisitions", [])
    if acq:
        subsection("ì¸ìˆ˜/ë§¤ê°")
        for i, news in enumerate(acq[:3], 1):
            print(f"  [{i}] {news[:70]}...")

    if not rate and not occ and not acq:
        print("  ìµœê·¼ ë¶€ë™ì‚° ê´€ë ¨ ì´‰ë§¤ ì—†ìŒ")


def print_8k_events(events: list):
    """8-K ì´ë²¤íŠ¸ ì¶œë ¥"""
    section("8-K ì£¼ìš” ê³µì‹œ", "ğŸ“¢")

    if not events:
        print("  ìµœê·¼ 8-K ê³µì‹œ ì—†ìŒ")
        return

    for event in events[:5]:
        date = event.get('date', '')
        event_type = event.get('type', 'ê¸°íƒ€')
        importance = event.get('importance', '')

        print(f"  {importance} {date}: {event_type}")


def print_sec_info(sec_info: dict):
    """SEC ê³µì‹œ ì •ë³´"""
    section("SEC ê³µì‹œ ë¶„ì„", "ğŸ“‹")

    # ìˆ«ì í‘œì‹œ
    subsection("SEC í‚¤ì›Œë“œ ì–¸ê¸‰ íšŸìˆ˜ (2024ë…„~)")
    print(f"  Warrant ì–¸ê¸‰: {sec_info.get('warrant_mentions', 0)}ê±´")
    print(f"  Dilution ì–¸ê¸‰: {sec_info.get('dilution_mentions', 0)}ê±´")
    print(f"  Covenant/ë¹š ì¡°í•­: {sec_info.get('covenant_mentions', 0)}ê±´")
    print(f"  Debt ì–¸ê¸‰: {sec_info.get('debt_mentions', 0)}ê±´")
    print(f"  Lock-up ì–¸ê¸‰: {sec_info.get('lockup_mentions', 0)}ê±´")
    print(f"  S-3/424B (ì˜¤í¼ë§): {sec_info.get('offering_mentions', 0)}ê±´")

    subsection("ë‰´ìŠ¤ ë¶„ì„ (2025ë…„)")
    print(f"  í˜¸ì¬ ê´€ë ¨: {sec_info.get('positive_news', 0)}ê±´")
    print(f"  ì•…ì¬ ê´€ë ¨: {sec_info.get('negative_news', 0)}ê±´")

    # ë¦¬ìŠ¤í¬ í•´ì„
    subsection("ë¦¬ìŠ¤í¬ í•´ì„")
    risks = []
    safe = []

    if sec_info.get("has_warrant_risk"):
        risks.append("âš ï¸ ì›ŒëŸ°íŠ¸ ë¦¬ìŠ¤í¬ (í¬ì„ ê°€ëŠ¥ì„±)")
    else:
        safe.append("âœ… ì›ŒëŸ°íŠ¸ ë¦¬ìŠ¤í¬ ë‚®ìŒ")

    if sec_info.get("dilution_risk"):
        risks.append("âš ï¸ í¬ì„ ë¦¬ìŠ¤í¬ (Dilution ì–¸ê¸‰ å¤š)")
    else:
        safe.append("âœ… í¬ì„ ë¦¬ìŠ¤í¬ ë‚®ìŒ")

    if sec_info.get("has_debt_covenant"):
        risks.append("âš ï¸ ë¹š/Covenant ì¡°í•­ ìˆìŒ")
    else:
        safe.append("âœ… Covenant ë¦¬ìŠ¤í¬ ë‚®ìŒ")

    if sec_info.get("has_offering_risk"):
        risks.append("âš ï¸ ì˜¤í¼ë§ ë¦¬ìŠ¤í¬ (S-3/424B ë“±ë¡)")
    else:
        safe.append("âœ… ì˜¤í¼ë§ ë¦¬ìŠ¤í¬ ë‚®ìŒ")

    if sec_info.get("has_lockup"):
        print("  ğŸ”’ Lock-up ì¡°í•­ ì¡´ì¬ (ë‚´ë¶€ì ë§¤ë„ ì œí•œ)")

    if sec_info.get("has_positive_news"):
        safe.append("ğŸ”¥ í˜¸ì¬ ê³µì‹œ å¤š")
    if sec_info.get("has_negative_news"):
        risks.append("âŒ ì•…ì¬ ê³µì‹œ å¤š")

    if risks:
        for r in risks:
            print(f"  {r}")
    if safe:
        for s in safe:
            print(f"  {s}")

    if not risks and not safe:
        print("  íŠ¹ì´ì‚¬í•­ ì—†ìŒ")


def print_ftd_data(ftd: dict):
    """FTD ë°ì´í„° ì¶œë ¥"""
    section("FTD (Failure to Deliver)", "ğŸ“¦")

    if not ftd.get("recent_ftd"):
        print("  FTD ë°ì´í„° ì—†ìŒ")
        return

    print(f"  ì´ FTD: {fmt_num(ftd.get('total_ftd'))}ì£¼")
    print(f"  í‰ê·  FTD: {fmt_num(ftd.get('avg_ftd'))}ì£¼")
    print(f"  ìµœëŒ€ FTD: {fmt_num(ftd.get('max_ftd'))}ì£¼")
    print(f"  ì¶”ì„¸: {ftd.get('ftd_trend', 'N/A')}")

    if ftd.get("has_significant_ftd"):
        print(f"\n  ğŸ”¥ ìœ ì˜ë¯¸í•œ FTD ê°ì§€! (10ë§Œì£¼+)")

    subsection("ìµœê·¼ FTD")
    for f in ftd.get("recent_ftd", [])[:5]:
        print(f"    {f['date']}: {fmt_num(f['quantity'])}ì£¼")


def print_options_data(opt: dict):
    """ì˜µì…˜ ë°ì´í„° ì¶œë ¥"""
    section("ì˜µì…˜ ì²´ì¸ ë¶„ì„", "ğŸ“Š")

    if not opt.get("has_options"):
        print("  ì˜µì…˜ ê±°ë˜ ì—†ìŒ")
        return

    print(f"  ê°€ì¥ ê°€ê¹Œìš´ ë§Œê¸°: {opt.get('nearest_expiry')}")
    print(f"  ì½œ OI ì´í•©: {fmt_num(opt.get('total_call_oi'))}")
    print(f"  í’‹ OI ì´í•©: {fmt_num(opt.get('total_put_oi'))}")
    print(f"  Put/Call ë¹„ìœ¨: {opt.get('put_call_ratio', 0):.2f}")
    print(f"  Max Pain: ${opt.get('max_pain', 0):.2f}")
    print(f"  ITM ì½œ OI: {fmt_num(opt.get('itm_calls'))}")

    if opt.get("gamma_exposure"):
        subsection("ê°ë§ˆ ì§‘ì¤‘ êµ¬ê°„ (OI Top 5)")
        for g in opt.get("gamma_exposure", []):
            print(f"    ${g['strike']:.2f}: {fmt_num(g['oi'])} OI")


def print_social_sentiment(sent: dict):
    """ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ ì¶œë ¥"""
    section("ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸", "ğŸ’¬")

    print(f"  ì¢…í•© ì„¼í‹°ë¨¼íŠ¸: {sent.get('overall_sentiment', 'N/A')}")

    if sent.get("stocktwits_sentiment"):
        print(f"  Stocktwits: {sent['stocktwits_sentiment']} ({sent.get('stocktwits_messages', 0)}ê°œ ë©”ì‹œì§€)")

    if sent.get("watchlist_count"):
        print(f"  ê´€ì‹¬ëª©ë¡ ë“±ë¡: {fmt_num(sent.get('watchlist_count'))}ëª…")

    if sent.get("reddit_mentions"):
        print(f"  Reddit ì–¸ê¸‰: {sent['reddit_mentions']}ê°œ")

    if sent.get("recent_posts"):
        subsection("ìµœê·¼ í¬ìŠ¤íŠ¸")
        for p in sent.get("recent_posts", [])[:5]:
            source = p.get('source', 'Unknown')
            sentiment = p.get('sentiment', 'N/A')
            emoji = "ğŸŸ¢" if sentiment == 'Bullish' else "ğŸ”´" if sentiment == 'Bearish' else "âšª"
            print(f"    [{source}] {emoji} {p['body'][:50]}...")


def print_catalyst(cat: dict):
    """ì´‰ë§¤ ì¼ì • ì¶œë ¥"""
    section("ì´‰ë§¤(Catalyst) ì¼ì •", "ğŸ“…")

    if cat.get("next_earnings"):
        print(f"  ë‹¤ìŒ ì–´ë‹: {cat['next_earnings']}")

    if cat.get("recent_earnings_surprise"):
        print(f"  ìµœê·¼ ì–´ë‹ ì„œí”„ë¼ì´ì¦ˆ: {cat['recent_earnings_surprise']}")

    if cat.get("ex_dividend_date"):
        print(f"  ë°°ë‹¹ë½ì¼: {cat['ex_dividend_date']}")

    if cat.get("earnings_estimate"):
        print(f"  ëª©í‘œê°€ í‰ê· : ${cat['earnings_estimate']:.2f}")

    if not any([cat.get("next_earnings"), cat.get("ex_dividend_date")]):
        print("  ì˜ˆì •ëœ ì´‰ë§¤ ì—†ìŒ")


def print_fibonacci(fib: dict):
    """í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ì¶œë ¥"""
    section("í”¼ë³´ë‚˜ì¹˜ & ì§€ì§€/ì €í•­", "ğŸ“")

    if not fib.get("levels"):
        print("  ë°ì´í„° ë¶€ì¡±")
        return

    print(f"  í˜„ì¬ ìœ„ì¹˜: {fib.get('current_zone', 'N/A')}")

    subsection("í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨")
    for level, price in fib.get("levels", {}).items():
        print(f"    {level}: ${price}")

    if fib.get("support_levels"):
        subsection("ì§€ì§€ì„  (í˜„ì¬ê°€ ì•„ë˜)")
        for s in fib.get("support_levels", [])[:3]:
            print(f"    {s['level']}: ${s['price']} ({s['distance']} ì•„ë˜)")

    if fib.get("resistance_levels"):
        subsection("ì €í•­ì„  (í˜„ì¬ê°€ ìœ„)")
        for r in fib.get("resistance_levels", [])[:3]:
            print(f"    {r['level']}: ${r['price']} ({r['distance']} ìœ„)")

    if fib.get("gaps"):
        subsection("ê°­ ë¶„ì„ (ìµœê·¼ 20ì¼)")
        for g in fib.get("gaps", [])[:5]:
            print(f"    {g['date']}: {g['type']} ${g['gap_start']}-${g['gap_end']} [{g['filled']}]")


def print_volume_profile(vp: dict):
    """ë³¼ë¥¨ í”„ë¡œíŒŒì¼ ì¶œë ¥"""
    section("ë³¼ë¥¨ í”„ë¡œíŒŒì¼", "ğŸ“Š")

    if not vp.get("poc"):
        print("  ë°ì´í„° ë¶€ì¡±")
        return

    print(f"  POC (ê±°ë˜ëŸ‰ ì§‘ì¤‘ê°€): ${vp.get('poc')}")
    print(f"  Value Area High: ${vp.get('value_area_high')}")
    print(f"  Value Area Low: ${vp.get('value_area_low')}")

    if vp.get("high_volume_zones"):
        subsection("ê³ ê±°ë˜ëŸ‰ ê°€ê²©ëŒ€")
        for z in vp.get("high_volume_zones", [])[:5]:
            print(f"    ${z['price']}: {fmt_num(z['volume'])}ì£¼")


def print_darkpool(dp: dict):
    """ë‹¤í¬í’€ ë°ì´í„° ì¶œë ¥"""
    section("ë‹¤í¬í’€ & ìˆë³¼ë¥¨", "ğŸŒ‘")

    if dp.get("source"):
        print(f"  ğŸ“¡ ì†ŒìŠ¤: {dp['source']}")

    if dp.get("short_volume_percent"):
        print(f"  ìˆ ë³¼ë¥¨ ë¹„ìœ¨: {dp['short_volume_percent']}%")

    if dp.get("off_exchange_percent"):
        print(f"  ì¥ì™¸ê±°ë˜(ë‹¤í¬í’€) ë¹„ìœ¨: {dp['off_exchange_percent']}%")

    if dp.get("darkpool_volume"):
        print(f"  ë‹¤í¬í’€ ê±°ë˜ëŸ‰: {fmt_num(dp['darkpool_volume'])}ì£¼")

    if dp.get("warning"):
        print(f"\n  {dp['warning']}")

    if dp.get("dp_warning"):
        print(f"  {dp['dp_warning']}")

    if not dp.get("short_volume_percent") and not dp.get("off_exchange_percent"):
        print("  ë°ì´í„° ì—†ìŒ")


def print_sec_filings(filings: dict):
    """SEC Filing ì¶œë ¥"""
    section("SEC Filing ìƒì„¸", "ğŸ“‘")

    if filings.get("company_name"):
        print(f"  SEC ë“±ë¡ëª…: {filings['company_name']}")

    if filings.get("cik"):
        print(f"  CIK: {filings['cik']}")

    if filings.get("insider_lockup_price"):
        print(f"\n  ğŸ”’ ë‚´ë¶€ì ë½ì—… ê°€ê²©: {filings['insider_lockup_price']}")

    if filings.get("lockup_info"):
        print(f"  ğŸ”’ ë½ì—… ì •ë³´: {filings['lockup_info']}")

    # SPAC / Earnout ì •ë³´
    if filings.get("is_spac"):
        print(f"\n  ğŸš€ SPAC í•©ë³‘ ì¢…ëª©!")

    if filings.get("earnout_prices"):
        subsection("Earnout ì¡°ê±´ (ë½ì—… í•´ì œ ê°€ê²©)")
        for price in filings["earnout_prices"]:
            print(f"    ğŸ¯ ì£¼ê°€ {price} ë„ë‹¬ ì‹œ â†’ ì£¼ì‹ ë½ì—… í•´ì œ")
        print(f"    ğŸ’¡ ì´ ê°€ê²©ë“¤ì—ì„œ ë‚´ë¶€ì/ìŠ¤í°ì„œê°€ ë§¤ë„ ê°€ëŠ¥í•´ì§ (ê³µê¸‰ ì¦ê°€)")

    if filings.get("earnout_shares"):
        print(f"  ğŸ“ˆ Earnout ëŒ€ìƒ ì£¼ì‹ ìˆ˜: {filings['earnout_shares']}ì£¼")

    if filings.get("warrant_details"):
        subsection("ì›ŒëŸ°íŠ¸ í–‰ì‚¬ê°€")
        for w in filings["warrant_details"]:
            print(f"    ğŸ’° {w}")

    if filings.get("debt_details"):
        subsection("ë¹š/ëŒ€ì¶œ ì •ë³´")
        for d in filings["debt_details"]:
            print(f"    ğŸ’³ {d}")

    if filings.get("offering_info"):
        subsection("ì˜¤í¼ë§ ì´ë ¥")
        for o in filings["offering_info"]:
            print(f"    ğŸ“„ {o['date']}: {o['shares']}ì£¼ @ {o['price']} ({o['form']})")

    if filings.get("recent_filings"):
        subsection("ìµœê·¼ SEC ê³µì‹œ")
        for f in filings["recent_filings"][:7]:
            form_emoji = "ğŸ“‹"
            if f['form'] in ['S-1', 'S-3', '424B4', '424B5']:
                form_emoji = "âš ï¸"
            elif f['form'] in ['S-4', 'S-4/A', 'DEFM14A']:
                form_emoji = "ğŸš€"  # SPAC ê´€ë ¨
            elif f['form'] == '8-K':
                form_emoji = "ğŸ“¢"
            elif f['form'] in ['10-K', '10-Q']:
                form_emoji = "ğŸ“Š"
            print(f"    {form_emoji} {f['date']}: {f['form']}")

    if not filings.get("recent_filings") and not filings.get("insider_lockup_price"):
        print("  SEC ë°ì´í„° ì—†ìŒ")


def print_institutional(inst: dict):
    """ê¸°ê´€ ë³´ìœ  ì¶œë ¥"""
    section("ê¸°ê´€ ë³´ìœ  í˜„í™©", "ğŸ›ï¸")

    print(f"  ê¸°ê´€ ë³´ìœ  ë¹„ìœ¨: {inst.get('institutional_percent', 'N/A')}")
    print(f"  ê¸°ê´€ ìˆ˜: {inst.get('total_institutional', 0)}ê°œ")

    if inst.get("top_holders"):
        subsection("Top 5 ê¸°ê´€")
        for h in inst["top_holders"]:
            print(f"    {h['holder'][:25]}: {fmt_num(h['shares'])}ì£¼ ({h['pct_out']})")


def print_peer_comparison(peer: dict):
    """ë™ì¢…ì—…ì²´ ë¹„êµ ì¶œë ¥"""
    section("ë™ì¢…ì—…ì²´ ë¹„êµ", "ğŸ­")

    print(f"  ì„¹í„°: {peer.get('sector', 'N/A')}")
    print(f"  ì‚°ì—…: {peer.get('industry', 'N/A')}")
    print(f"  ì„¹í„° í‰ê·  PE: {peer.get('sector_avg_pe', 'N/A')}")
    print(f"  ìƒëŒ€ ë°¸ë¥˜ì—ì´ì…˜: {peer.get('relative_valuation', 'N/A')}")


def print_short_history(sh: dict):
    """Short Interest íˆìŠ¤í† ë¦¬ ì¶œë ¥"""
    section("Short Interest ì¶”ì´", "ğŸ“‰")

    if sh.get("current_si"):
        print(f"  í˜„ì¬ SI: {fmt_num(sh['current_si'])}ì£¼")
    if sh.get("prior_si"):
        print(f"  ì „ì›” SI: {fmt_num(sh['prior_si'])}ì£¼")

    print(f"  30ì¼ ë³€í™”: {sh.get('change_30d', 'N/A')}")
    print(f"  ì¶”ì„¸: {sh.get('trend', 'N/A')}")

    if sh.get("short_float_pct"):
        print(f"  Short Float %: {sh['short_float_pct']}")

    if sh.get("short_ratio"):
        print(f"  Short Ratio: {sh['short_ratio']}ì¼")

    if sh.get("short_volume"):
        print(f"  Short Volume: {fmt_num(int(sh['short_volume']))}ì£¼")


# ============================================================
# ë©”ì¸ ë¶„ì„
# ============================================================

def analyze(ticker: str, use_ai: bool = True, force_normal: bool = False):
    """ì¢…í•© ë¶„ì„ ì‹¤í–‰"""

    mode = "ì¼ë°˜ íˆ¬ì" if force_normal else "ìë™ (ìˆìŠ¤í€´ì¦ˆ/ì¼ë°˜)"
    print(f"\n{'#'*70}")
    print(f"#  ğŸ” {ticker} ì´ˆì •ë°€ ë¶„ì„ ë¦¬í¬íŠ¸ v3 (ë˜¥ê¾¸ë© ì£¼ë¦„ ì—ë””ì…˜)")
    print(f"#  ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"#  ğŸ¤– Gemini AI: {'ON' if use_ai else 'OFF'}")
    print(f"#  ğŸ“Š ë¶„ì„ ëª¨ë“œ: {mode}")
    print(f"{'#'*70}")

    try:
        # ========== ë°ì´í„° ìˆ˜ì§‘ ==========
        print("\nâ³ ë°ì´í„° ìˆ˜ì§‘ ì¤‘... (ì´ˆì •ë°€ ë¶„ì„ v3)")

        # 1. yfinance ê¸°ë³¸ ì •ë³´
        print("  â†’ yfinance ê¸°ë³¸ ì •ë³´...")
        data = get_basic_info(ticker)
        stock = data['stock']

        # 2. Borrow ë°ì´í„° (Zero Borrow í¬í•¨)
        print("  â†’ Borrow Rate & Zero Borrow...")
        borrow = get_borrow_data(ticker)

        # 3. RegSHO
        print("  â†’ RegSHO Threshold...")
        in_regsho = check_regsho(ticker)

        # 4. ê¸°ìˆ ì  ì§€í‘œ
        print("  â†’ ê¸°ìˆ ì  ë¶„ì„...")
        tech = get_technicals(stock)

        # 5. ê²½ì˜ì§„ & ë‚´ë¶€ì
        print("  â†’ ê²½ì˜ì§„ & ë‚´ë¶€ì...")
        officers = get_officers(stock)
        insider_tx = get_insider_transactions(stock)
        inst_holders = get_institutional_holders(stock)

        # 6. ë‰´ìŠ¤ (ì„¹í„°ë³„ íŠ¹í™”)
        print("  â†’ ë‰´ìŠ¤...")
        news = get_news(stock)
        if not news:
            news = search_recent_news(ticker)

        # 6.5 ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤
        print("  â†’ ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤...")
        sector = data.get('sector', '')
        industry = data.get('industry', '')
        sector_news = get_sector_news(ticker, sector, industry)

        # 6.6 ì„¹í„°ë³„ ì´‰ë§¤ ë¶„ì„
        sector_catalysts = None
        sector_catalyst_type = None
        company_name = data.get('name', ticker)
        industry_lower = (industry or "").lower()
        sector_lower = (sector or "").lower()

        if "biotech" in industry_lower or "pharma" in industry_lower or "healthcare" in sector_lower:
            print("  â†’ ë°”ì´ì˜¤í… ì´‰ë§¤ ë¶„ì„ (FDA/ì„ìƒ)...")
            sector_catalysts = get_biotech_catalysts(ticker, company_name)
            sector_catalyst_type = "biotech"
        elif "auto" in industry_lower or "vehicle" in industry_lower or "ev" in industry_lower:
            print("  â†’ ìë™ì°¨/EV ì´‰ë§¤ ë¶„ì„...")
            sector_catalysts = get_automotive_catalysts(ticker, company_name)
            sector_catalyst_type = "automotive"
        elif "real estate" in sector_lower or "reit" in industry_lower:
            # REIT ì²´í¬ë¥¼ retail ì•ì— (REIT - Retail êµ¬ë¶„)
            print("  â†’ ë¶€ë™ì‚°/ë¦¬ì¸  ì´‰ë§¤ ë¶„ì„...")
            sector_catalysts = get_realestate_catalysts(ticker, company_name)
            sector_catalyst_type = "realestate"
        elif "retail" in industry_lower or "e-commerce" in industry_lower or "store" in industry_lower:
            print("  â†’ ë¦¬í…Œì¼ ì´‰ë§¤ ë¶„ì„...")
            sector_catalysts = get_retail_catalysts(ticker, company_name)
            sector_catalyst_type = "retail"
        elif "food" in industry_lower or "beverage" in industry_lower or "consumer" in sector_lower:
            print("  â†’ ì†Œë¹„ì¬ ì´‰ë§¤ ë¶„ì„...")
            sector_catalysts = get_retail_catalysts(ticker, company_name)  # ë¦¬í…Œì¼ê³¼ ìœ ì‚¬
            sector_catalyst_type = "consumer"
        elif "bank" in industry_lower or "financial" in sector_lower or "insurance" in industry_lower:
            print("  â†’ ê¸ˆìœµ ì´‰ë§¤ ë¶„ì„...")
            sector_catalysts = get_financial_catalysts(ticker, company_name)
            sector_catalyst_type = "financial"
        elif "industrial" in sector_lower or "aerospace" in industry_lower or "defense" in industry_lower:
            print("  â†’ ì‚°ì—…ì¬ ì´‰ë§¤ ë¶„ì„...")
            sector_catalysts = get_industrial_catalysts(ticker, company_name)
            sector_catalyst_type = "industrial"

        # 7. SEC ê³µì‹œ ì •ë³´ (ë¹š, covenant, í¬ì„ ë¦¬ìŠ¤í¬)
        print("  â†’ SEC ê³µì‹œ í‚¤ì›Œë“œ ë¶„ì„...")
        sec_info = get_sec_info(ticker)

        # 8. FTD ë°ì´í„°
        print("  â†’ FTD (Failure to Deliver)...")
        ftd_data = get_ftd_data(ticker)

        # 9. ì˜µì…˜ ì²´ì¸
        print("  â†’ ì˜µì…˜ ì²´ì¸ ë¶„ì„...")
        options_data = get_options_data(stock)

        # 10. ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸
        print("  â†’ ì†Œì…œ ì„¼í‹°ë¨¼íŠ¸ (Stocktwits)...")
        sentiment_data = get_social_sentiment(ticker)

        # 11. ì´‰ë§¤ ì¼ì •
        print("  â†’ ì´‰ë§¤ ì¼ì •...")
        catalyst_data = get_catalyst_calendar(stock)

        # 12. í”¼ë³´ë‚˜ì¹˜ & ì§€ì§€/ì €í•­
        print("  â†’ í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨...")
        fib_data = get_fibonacci_levels(stock)

        # 13. ë³¼ë¥¨ í”„ë¡œíŒŒì¼
        print("  â†’ ë³¼ë¥¨ í”„ë¡œíŒŒì¼...")
        volume_profile = get_volume_profile(stock)

        # 14. ë‹¤í¬í’€
        print("  â†’ ë‹¤í¬í’€ ë°ì´í„°...")
        darkpool_data = get_darkpool_data(ticker)

        # 15. SEC Filing ìƒì„¸ (S-1, ë½ì—…, ì›ŒëŸ°íŠ¸)
        print("  â†’ SEC Filing ìƒì„¸ íŒŒì‹±...")
        sec_filings = get_sec_filings(ticker)

        # 15.5 8-K ì£¼ìš” ì´ë²¤íŠ¸ íŒŒì‹±
        print("  â†’ 8-K ì£¼ìš” ì´ë²¤íŠ¸ íŒŒì‹±...")
        cik = sec_filings.get("cik", "")
        eight_k_events = parse_8k_content(ticker, cik)

        # 16. ê¸°ê´€ ë³´ìœ  ë³€í™”
        print("  â†’ ê¸°ê´€ ë³´ìœ  ë¶„ì„...")
        institutional_data = get_institutional_changes(stock)

        # 17. ë™ì¢…ì—…ì²´ ë¹„êµ
        print("  â†’ ë™ì¢…ì—…ì²´ ë¹„êµ...")
        peer_data = get_peer_comparison(stock, ticker)

        # 18. Short Interest íˆìŠ¤í† ë¦¬
        print("  â†’ Short Interest ì¶”ì´...")
        short_history = get_short_history(ticker)

        # 19. ìŠ¤í€´ì¦ˆ ì ìˆ˜
        print("  â†’ ìŠ¤í€´ì¦ˆ ì ìˆ˜ ê³„ì‚°...")
        score_info = calculate_squeeze_score_v3(data, borrow, in_regsho, tech)

        print("\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")

        # ========== ì¶œë ¥ ==========

        # ê¸°ë³¸ ì •ë³´
        print_basic_info(data)
        print_price_info(data)

        # ìˆìŠ¤í€´ì¦ˆ ê´€ë ¨
        print_short_data(data, borrow, in_regsho)
        print_short_history(short_history)
        print_ftd_data(ftd_data)

        # ê¸°ìˆ ì  ë¶„ì„
        print_technicals(tech, data.get('price', 0))
        print_fibonacci(fib_data)
        print_volume_profile(volume_profile)

        # ì˜µì…˜ & ë‹¤í¬í’€
        print_options_data(options_data)
        print_darkpool(darkpool_data)

        # ìŠ¤í€´ì¦ˆ ì ìˆ˜
        print_squeeze_score(score_info)

        # SEC ë¶„ì„
        print_sec_info(sec_info)
        print_sec_filings(sec_filings)

        # ê¸°ê´€ & ë™ì¢…ì—…ì²´
        print_institutional(institutional_data)
        print_peer_comparison(peer_data)

        # ì´‰ë§¤ & ì„¼í‹°ë¨¼íŠ¸
        print_catalyst(catalyst_data)
        print_social_sentiment(sentiment_data)

        # ê²½ì˜ì§„ & ë‰´ìŠ¤
        print_officers(officers)
        print_news(news)

        # ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤
        print_sector_news(sector_news)

        # 8-K ì£¼ìš” ì´ë²¤íŠ¸
        print_8k_events(eight_k_events)

        # ì„¹í„°ë³„ ì´‰ë§¤ (í•´ë‹¹ì‹œ)
        if sector_catalysts:
            if sector_catalyst_type == "biotech":
                print_biotech_catalysts(sector_catalysts)
            elif sector_catalyst_type == "automotive":
                print_automotive_catalysts(sector_catalysts)
            elif sector_catalyst_type == "retail" or sector_catalyst_type == "consumer":
                print_retail_catalysts(sector_catalysts)
            elif sector_catalyst_type == "financial":
                print_financial_catalysts(sector_catalysts)
            elif sector_catalyst_type == "industrial":
                print_industrial_catalysts(sector_catalysts)
            elif sector_catalyst_type == "realestate":
                print_realestate_catalysts(sector_catalysts)

        # ========== Gemini AI ë¶„ì„ ==========

        if use_ai:
            section("Gemini AI ì¢…í•© ë¶„ì„", "ğŸ¤–")
            print("\n  â³ AI ë¶„ì„ ì¤‘...")
            ai_analysis = analyze_with_gemini(
                ticker, data, borrow, tech, in_regsho, score_info, news, force_normal, sec_info, sec_filings
            )
            print(f"\n{ai_analysis}")

        # ========== ìµœì¢… ìš”ì•½ ==========

        section("ìµœì¢… ìš”ì•½", "ğŸ’¡")

        price = data.get('price', 0)
        post = data.get('post_market')
        score = score_info['score']

        print(f"\n  ğŸ“Š {data['name']} ({ticker})")
        print(f"  ğŸ’° í˜„ì¬ê°€: ${price:.2f}")
        if post:
            print(f"  ğŸŒ™ ì• í”„í„°: ${post:.2f} ({((post/price)-1)*100:+.1f}%)")
        print(f"  ğŸ° ìŠ¤í€´ì¦ˆ ì ìˆ˜: {score}/100")

        if borrow.get("is_zero_borrow"):
            print(f"\n  ğŸ”¥ ZERO BORROW ìƒíƒœ!")
            print(f"     â†’ ìƒˆ ìˆ ì§„ì… ë¶ˆê°€")
            print(f"     â†’ ê¸°ì¡´ ìˆ íƒˆì¶œ = ì‹œì¥ ë§¤ìˆ˜ í•„ìˆ˜")
            print(f"     â†’ ìŠ¤í€´ì¦ˆ ì¡°ê±´ ì¶©ì¡±!")

        print(f"\n{'='*70}")
        print(f"âš ï¸ íˆ¬ì ê²°ì •ì€ ë³¸ì¸ ì±…ì„ì…ë‹ˆë‹¤.")
        print(f"{'='*70}\n")

        return {
            "data": data,
            "borrow": borrow,
            "tech": tech,
            "in_regsho": in_regsho,
            "score_info": score_info
        }

    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    if len(sys.argv) < 2:
        print("Usage: uv run python deep_analyzer.py <TICKER> [OPTIONS]")
        print("Example: uv run python deep_analyzer.py BNAI")
        print("         uv run python deep_analyzer.py BNAI --no-ai")
        print("         uv run python deep_analyzer.py GLSI --normal  # ì¼ë°˜ íˆ¬ì ë¶„ì„")
        sys.exit(1)

    ticker = sys.argv[1].upper()
    use_ai = "--no-ai" not in sys.argv
    force_normal = "--normal" in sys.argv

    analyze(ticker, use_ai, force_normal)


if __name__ == "__main__":
    main()
