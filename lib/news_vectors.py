"""
lib/news_vectors.py - ë‰´ìŠ¤ ë²¡í„° DB ì‹œìŠ¤í…œ

Gemini ì„ë² ë”© â†’ pgvector ì €ì¥ â†’ ì¤‘ë³µê°ì§€/ìœ ì‚¬ë‰´ìŠ¤ì—°ê²°/ì‹œê°„ê°€ì¤‘ì¹˜/ì‹œì¥ë°˜ì˜ì²´í¬/ìë™ì •ë¦¬

Usage:
    from lib.news_vectors import embed_and_dedup, init_vector_tables
    init_vector_tables()
    embed_and_dedup()
"""

import sys
import os
from datetime import datetime, timedelta

import psycopg2
from psycopg2.extras import RealDictCursor

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from db import get_db
from api.embeddings import get_embedding, get_embeddings_batch


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í…Œì´ë¸” ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def init_vector_tables():
    """news_vectors, news_links í…Œì´ë¸” ìƒì„±"""
    conn = get_db()
    cur = conn.cursor()

    try:
        # pgvector í™•ì¥ í™œì„±í™”
        cur.execute("CREATE EXTENSION IF NOT EXISTS vector")

        # news_vectors í…Œì´ë¸”
        cur.execute("""
            CREATE TABLE IF NOT EXISTS news_vectors (
                id SERIAL PRIMARY KEY,
                news_mention_id INTEGER NOT NULL REFERENCES news_mentions(id) ON DELETE CASCADE,
                ticker VARCHAR(10) NOT NULL,
                headline_text TEXT NOT NULL,
                embedding vector(768) NOT NULL,
                is_duplicate BOOLEAN DEFAULT FALSE,
                duplicate_of_id INTEGER REFERENCES news_vectors(id) ON DELETE SET NULL,
                is_reflected BOOLEAN DEFAULT FALSE,
                reflected_price_change FLOAT,
                reflected_at TIMESTAMPTZ,
                is_active BOOLEAN DEFAULT TRUE,
                time_weight FLOAT DEFAULT 1.0,
                created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(news_mention_id)
            )
        """)

        # news_links í…Œì´ë¸” (ìœ ì‚¬ ë‰´ìŠ¤ ì—°ê²°)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS news_links (
                id SERIAL PRIMARY KEY,
                source_id INTEGER NOT NULL REFERENCES news_vectors(id) ON DELETE CASCADE,
                target_id INTEGER NOT NULL REFERENCES news_vectors(id) ON DELETE CASCADE,
                similarity FLOAT NOT NULL,
                created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(source_id, target_id),
                CHECK(source_id < target_id)
            )
        """)

        # ì¸ë±ìŠ¤ ìƒì„± (IF NOT EXISTS ì§€ì› ì•ˆ í•˜ë¯€ë¡œ try/except)
        for idx_sql in [
            "CREATE INDEX idx_nv_ticker ON news_vectors(ticker)",
            "CREATE INDEX idx_nv_active ON news_vectors(is_active, is_duplicate)",
            "CREATE INDEX idx_nv_created ON news_vectors(created_at)",
        ]:
            try:
                cur.execute(idx_sql)
            except psycopg2.errors.DuplicateTable:
                conn.rollback()
                # ì¬ì—°ê²° í•„ìš” ì—†ì´ ë‹¤ìŒ ì¸ë±ìŠ¤ ì‹œë„
                cur = conn.cursor()

        conn.commit()
        print("  âœ… news_vectors, news_links í…Œì´ë¸” ì¤€ë¹„ ì™„ë£Œ")
    except Exception as e:
        conn.rollback()
        print(f"  âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")
        raise
    finally:
        cur.close()
        conn.close()


def _ensure_ivfflat_index(conn):
    """IVFFlat ì¸ë±ìŠ¤ ìƒì„± (í–‰ì´ ì¶©ë¶„í•  ë•Œë§Œ)"""
    cur = conn.cursor()
    try:
        cur.execute("SELECT COUNT(*) FROM news_vectors")
        count = cur.fetchone()[0]

        # IVFFlatì€ ìµœì†Œ lists * 10 í–‰ í•„ìš” (lists=100 â†’ 1000í–‰)
        if count >= 1000:
            cur.execute("""
                SELECT indexname FROM pg_indexes
                WHERE tablename = 'news_vectors' AND indexname = 'idx_nv_embedding'
            """)
            if not cur.fetchone():
                cur.execute("""
                    CREATE INDEX idx_nv_embedding ON news_vectors
                    USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)
                """)
                conn.commit()
                print(f"  ğŸ“ IVFFlat ì¸ë±ìŠ¤ ìƒì„± ({count}í–‰)")
    except Exception:
        conn.rollback()
    finally:
        cur.close()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ì§„ì…ì : embed_and_dedup
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def embed_and_dedup(ticker_filter: str | None = None):
    """
    ë¯¸ì„ë² ë”© ë‰´ìŠ¤ â†’ ë²¡í„°í™” â†’ ì¤‘ë³µ/ìœ ì‚¬ ê²€ì‚¬

    Args:
        ticker_filter: íŠ¹ì • í‹°ì»¤ë§Œ ì²˜ë¦¬ (Noneì´ë©´ ì „ì²´)
    """
    conn = get_db()
    cur = conn.cursor(cursor_factory=RealDictCursor)

    try:
        # 1. news_mentionsì—ì„œ news_vectorsì— ì—†ëŠ” í–‰ ì¡°íšŒ
        query = """
            SELECT nm.id, nm.ticker, nm.headline
            FROM news_mentions nm
            LEFT JOIN news_vectors nv ON nm.id = nv.news_mention_id
            WHERE nv.id IS NULL
        """
        params = []
        if ticker_filter:
            query += " AND nm.ticker = %s"
            params.append(ticker_filter)

        query += " ORDER BY nm.id"
        cur.execute(query, params)
        rows = cur.fetchall()

        if not rows:
            print("  ğŸ“­ ìƒˆë¡œìš´ ë‰´ìŠ¤ ì—†ìŒ (ë²¡í„°í™” ìŠ¤í‚µ)")
            return

        print(f"\nğŸ”® ë‰´ìŠ¤ ë²¡í„°í™” ì‹œì‘: {len(rows)}ê±´")

        # 2. ë°°ì¹˜ ì„ë² ë”© ìƒì„±
        headlines = [row['headline'] for row in rows]
        embeddings = get_embeddings_batch(headlines)

        embedded = 0
        duplicates = 0
        linked = 0

        # 3. ê° ë‰´ìŠ¤ì— ëŒ€í•´ ì¤‘ë³µ/ìœ ì‚¬ ê²€ì‚¬ í›„ ì €ì¥
        insert_cur = conn.cursor()

        for row, embedding in zip(rows, embeddings):
            if embedding is None:
                continue

            ticker = row['ticker']
            embedding_str = _vec_to_str(embedding)

            # ì¤‘ë³µ ì²´í¬
            dup_id = check_duplicate(conn, ticker, embedding_str)

            if dup_id:
                # ì¤‘ë³µ â†’ is_duplicate=TRUE
                insert_cur.execute("""
                    INSERT INTO news_vectors
                    (news_mention_id, ticker, headline_text, embedding, is_duplicate, duplicate_of_id)
                    VALUES (%s, %s, %s, %s::vector, TRUE, %s)
                    ON CONFLICT (news_mention_id) DO NOTHING
                """, (row['id'], ticker, row['headline'], embedding_str, dup_id))
                duplicates += 1
            else:
                # ìƒˆ ë‰´ìŠ¤ ì‚½ì…
                insert_cur.execute("""
                    INSERT INTO news_vectors
                    (news_mention_id, ticker, headline_text, embedding)
                    VALUES (%s, %s, %s, %s::vector)
                    ON CONFLICT (news_mention_id) DO NOTHING
                    RETURNING id
                """, (row['id'], ticker, row['headline'], embedding_str))

                result = insert_cur.fetchone()
                if result:
                    new_id = result[0]
                    # ìœ ì‚¬ ë‰´ìŠ¤ ê²€ìƒ‰ & ì—°ê²°
                    similar = find_similar_news(conn, ticker, embedding_str, exclude_id=new_id)
                    for sim_id, sim_score in similar:
                        link_similar_news(conn, new_id, sim_id, sim_score)
                        linked += 1

            embedded += 1

        conn.commit()
        insert_cur.close()

        # IVFFlat ì¸ë±ìŠ¤ ì²´í¬
        _ensure_ivfflat_index(conn)

        print(f"  âœ… ë²¡í„°í™” ì™„ë£Œ: {embedded}ê±´ ì²˜ë¦¬, {duplicates}ê±´ ì¤‘ë³µ, {linked}ê±´ ìœ ì‚¬ì—°ê²°")

    except Exception as e:
        conn.rollback()
        print(f"  âŒ ë²¡í„°í™” ì˜¤ë¥˜: {e}")
    finally:
        cur.close()
        conn.close()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¤‘ë³µ/ìœ ì‚¬ ê°ì§€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def check_duplicate(conn, ticker: str, embedding_str: str, days: int = 7) -> int | None:
    """
    cosine similarity > 0.95 = ì¤‘ë³µ

    Returns:
        ì¤‘ë³µì¸ ê²½ìš° ê¸°ì¡´ news_vectors.id, ì•„ë‹ˆë©´ None
    """
    cur = conn.cursor()
    try:
        cur.execute("""
            SELECT id, 1 - (embedding <=> %s::vector) AS similarity
            FROM news_vectors
            WHERE ticker = %s
              AND is_duplicate = FALSE
              AND created_at > NOW() - INTERVAL '%s days'
            ORDER BY embedding <=> %s::vector
            LIMIT 1
        """, (embedding_str, ticker, days, embedding_str))

        row = cur.fetchone()
        if row and row[1] > 0.95:
            return row[0]
        return None
    finally:
        cur.close()


def find_similar_news(conn, ticker: str, embedding_str: str,
                      threshold: float = 0.7, exclude_id: int | None = None,
                      days: int = 7) -> list[tuple[int, float]]:
    """
    0.7 ~ 0.95 ì‚¬ì´ = ìœ ì‚¬ ë‰´ìŠ¤

    Returns:
        [(news_vectors_id, similarity_score), ...]
    """
    cur = conn.cursor()
    try:
        query = """
            SELECT id, 1 - (embedding <=> %s::vector) AS similarity
            FROM news_vectors
            WHERE ticker = %s
              AND is_duplicate = FALSE
              AND created_at > NOW() - INTERVAL '%s days'
        """
        params = [embedding_str, ticker, days]

        if exclude_id:
            query += " AND id != %s"
            params.append(exclude_id)

        query += """
            HAVING 1 - (embedding <=> %s::vector) BETWEEN %s AND 0.95
            ORDER BY similarity DESC
            LIMIT 10
        """
        # Can't use HAVING without GROUP BY, use subquery instead
        full_query = f"""
            SELECT id, similarity FROM (
                {query.replace('HAVING 1 - (embedding <=> %s::vector) BETWEEN %s AND 0.95', '')}
                ORDER BY embedding <=> %s::vector
                LIMIT 20
            ) sub
            WHERE similarity BETWEEN %s AND 0.95
            ORDER BY similarity DESC
            LIMIT 10
        """
        # Simpler approach: just filter in application
        cur.execute("""
            SELECT id, 1 - (embedding <=> %s::vector) AS similarity
            FROM news_vectors
            WHERE ticker = %s
              AND is_duplicate = FALSE
              AND created_at > NOW() - INTERVAL '%s days'
              {}
            ORDER BY embedding <=> %s::vector
            LIMIT 20
        """.format("AND id != %s" if exclude_id else ""),
            (embedding_str, ticker, days) +
            ((exclude_id,) if exclude_id else ()) +
            (embedding_str,))

        results = []
        for row in cur.fetchall():
            sim = row[1]
            if threshold <= sim <= 0.95:
                results.append((row[0], sim))
        return results
    finally:
        cur.close()


def link_similar_news(conn, source_id: int, target_id: int, similarity: float):
    """news_linksì— ìœ ì‚¬ ê´€ê³„ ì‚½ì… (source_id < target_id ë³´ì¥)"""
    cur = conn.cursor()
    try:
        # CHECK(source_id < target_id) ì œì•½ ì¤€ìˆ˜
        lo, hi = min(source_id, target_id), max(source_id, target_id)
        cur.execute("""
            INSERT INTO news_links (source_id, target_id, similarity)
            VALUES (%s, %s, %s)
            ON CONFLICT (source_id, target_id) DO NOTHING
        """, (lo, hi, similarity))
    finally:
        cur.close()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹œê°„ ê°€ì¤‘ì¹˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def calculate_time_weights():
    """
    ì‹œê°„ ê°€ì¤‘ì¹˜ ì¼ê´„ ì—…ë°ì´íŠ¸
    time_weight = max(0.1, 1.0 - (ë‚˜ì´_ì‹œê°„ / 168))
    is_reflected=TRUE â†’ weight = 0.0
    """
    conn = get_db()
    cur = conn.cursor()

    try:
        cur.execute("""
            UPDATE news_vectors
            SET time_weight = CASE
                WHEN is_reflected = TRUE THEN 0.0
                ELSE GREATEST(0.1,
                    1.0 - EXTRACT(EPOCH FROM (NOW() - created_at)) / 3600.0 / 168.0
                )
            END
            WHERE is_active = TRUE
        """)
        updated = cur.rowcount
        conn.commit()
        print(f"  â±ï¸ ì‹œê°„ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸: {updated}ê±´")
    except Exception as e:
        conn.rollback()
        print(f"  âŒ ì‹œê°„ ê°€ì¤‘ì¹˜ ì˜¤ë¥˜: {e}")
    finally:
        cur.close()
        conn.close()


def get_time_weighted_score(ticker: str, days: int = 1) -> dict:
    """
    íŠ¹ì • í‹°ì»¤ì˜ ì‹œê°„ê°€ì¤‘ ë‰´ìŠ¤ ì ìˆ˜ ì¡°íšŒ

    Returns:
        {
            'ticker': str,
            'weighted_count': float,  # ì‹œê°„ê°€ì¤‘ ë‰´ìŠ¤ ìˆ˜
            'total_count': int,       # ì „ì²´ ë‰´ìŠ¤ ìˆ˜
            'unique_count': int,      # ë¹„ì¤‘ë³µ ë‰´ìŠ¤ ìˆ˜
            'duplicate_count': int,   # ì¤‘ë³µ ë‰´ìŠ¤ ìˆ˜
        }
    """
    conn = get_db()
    cur = conn.cursor(cursor_factory=RealDictCursor)

    try:
        cur.execute("""
            SELECT
                COUNT(*) AS total_count,
                COUNT(*) FILTER (WHERE is_duplicate = FALSE) AS unique_count,
                COUNT(*) FILTER (WHERE is_duplicate = TRUE) AS duplicate_count,
                COALESCE(SUM(time_weight) FILTER (WHERE is_duplicate = FALSE), 0) AS weighted_count
            FROM news_vectors
            WHERE ticker = %s
              AND is_active = TRUE
              AND created_at > NOW() - INTERVAL '%s days'
        """, (ticker, days))

        row = cur.fetchone()
        return {
            'ticker': ticker,
            'weighted_count': float(row['weighted_count']),
            'total_count': row['total_count'],
            'unique_count': row['unique_count'],
            'duplicate_count': row['duplicate_count'],
        }
    finally:
        cur.close()
        conn.close()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹œì¥ ë°˜ì˜ ì²´í¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def check_market_reflection(tickers: list[str] | None = None):
    """
    ë‰´ìŠ¤ ë°œí–‰ í›„ +10% ì´ìƒ ìƒìŠ¹ â†’ is_reflected=TRUE

    yfinanceë¡œ ë‰´ìŠ¤ ì‹œì  vs í˜„ì¬ ê°€ê²© ë¹„êµ
    """
    import yfinance as yf

    conn = get_db()
    cur = conn.cursor(cursor_factory=RealDictCursor)

    try:
        query = """
            SELECT nv.id, nv.ticker, nv.created_at
            FROM news_vectors nv
            WHERE nv.is_active = TRUE
              AND nv.is_duplicate = FALSE
              AND nv.is_reflected = FALSE
              AND nv.created_at < NOW() - INTERVAL '1 day'
        """
        params = []
        if tickers:
            query += " AND nv.ticker = ANY(%s)"
            params.append(tickers)

        cur.execute(query, params)
        rows = cur.fetchall()

        if not rows:
            print("  ğŸ“Š ì‹œì¥ ë°˜ì˜ ì²´í¬: ëŒ€ìƒ ì—†ìŒ")
            return

        # í‹°ì»¤ë³„ ê·¸ë£¹í•‘
        ticker_groups: dict[str, list] = {}
        for row in rows:
            ticker_groups.setdefault(row['ticker'], []).append(row)

        reflected = 0
        update_cur = conn.cursor()

        for ticker, group in ticker_groups.items():
            try:
                stock = yf.Ticker(ticker)
                hist = stock.history(period="1mo")

                if hist.empty:
                    continue

                current_price = hist['Close'].iloc[-1]

                for row in group:
                    news_date = row['created_at'].date()
                    # ë‰´ìŠ¤ ë‚ ì§œ ì´í›„ì˜ ê°€ê²© ì°¾ê¸°
                    mask = hist.index.date >= news_date
                    if not mask.any():
                        continue

                    news_price = hist.loc[mask, 'Close'].iloc[0]
                    if news_price <= 0:
                        continue

                    price_change = (current_price - news_price) / news_price

                    if price_change >= 0.10:  # +10% ì´ìƒ
                        update_cur.execute("""
                            UPDATE news_vectors
                            SET is_reflected = TRUE,
                                reflected_price_change = %s,
                                reflected_at = NOW(),
                                time_weight = 0.0
                            WHERE id = %s
                        """, (price_change, row['id']))
                        reflected += 1

            except Exception:
                continue

        conn.commit()
        update_cur.close()
        print(f"  ğŸ“ˆ ì‹œì¥ ë°˜ì˜ ì²´í¬: {reflected}ê±´ ë°˜ì˜ë¨")

    except Exception as e:
        conn.rollback()
        print(f"  âŒ ì‹œì¥ ë°˜ì˜ ì²´í¬ ì˜¤ë¥˜: {e}")
    finally:
        cur.close()
        conn.close()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í´ë¦°ì—…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cleanup_old_news(reflected_days: int = 30, hard_delete_days: int = 90):
    """
    ë‰´ìŠ¤ ì •ë¦¬:
    - ë°˜ì˜ë¨ + 30ì¼+ â†’ is_active=FALSE (ì†Œí”„íŠ¸ ì‚­ì œ)
    - ë¹„í™œì„± + 90ì¼+ â†’ DELETE (í•˜ë“œ ì‚­ì œ)
    """
    conn = get_db()
    cur = conn.cursor()

    try:
        # ì†Œí”„íŠ¸ ì‚­ì œ: ë°˜ì˜ëœ ë‰´ìŠ¤ 30ì¼ í›„ ë¹„í™œì„±í™”
        cur.execute("""
            UPDATE news_vectors
            SET is_active = FALSE
            WHERE is_reflected = TRUE
              AND is_active = TRUE
              AND reflected_at < NOW() - INTERVAL '%s days'
        """, (reflected_days,))
        soft = cur.rowcount

        # í•˜ë“œ ì‚­ì œ: ë¹„í™œì„± 90ì¼ í›„ ì‚­ì œ
        cur.execute("""
            DELETE FROM news_vectors
            WHERE is_active = FALSE
              AND created_at < NOW() - INTERVAL '%s days'
        """, (hard_delete_days,))
        hard = cur.rowcount

        conn.commit()
        print(f"  ğŸ§¹ ë‰´ìŠ¤ ì •ë¦¬: {soft}ê±´ ë¹„í™œì„±í™”, {hard}ê±´ ì‚­ì œ")

    except Exception as e:
        conn.rollback()
        print(f"  âŒ ë‰´ìŠ¤ ì •ë¦¬ ì˜¤ë¥˜: {e}")
    finally:
        cur.close()
        conn.close()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹œë§¨í‹± ê²€ìƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def search_similar_news(query_text: str, ticker: str | None = None,
                        limit: int = 5) -> list[dict]:
    """
    ì‹œë§¨í‹± ê²€ìƒ‰ - ì¿¼ë¦¬ í…ìŠ¤íŠ¸ì™€ ìœ ì‚¬í•œ ë‰´ìŠ¤ ì¡°íšŒ

    Args:
        query_text: ê²€ìƒ‰ í…ìŠ¤íŠ¸
        ticker: íŠ¹ì • í‹°ì»¤ í•„í„° (ì˜µì…˜)
        limit: ê²°ê³¼ ìˆ˜

    Returns:
        [{'id', 'ticker', 'headline', 'similarity', 'created_at'}, ...]
    """
    embedding = get_embedding(query_text)
    if embedding is None:
        return []

    embedding_str = _vec_to_str(embedding)

    conn = get_db()
    cur = conn.cursor(cursor_factory=RealDictCursor)

    try:
        query = """
            SELECT
                nv.id,
                nv.ticker,
                nv.headline_text AS headline,
                1 - (nv.embedding <=> %s::vector) AS similarity,
                nv.created_at,
                nv.is_duplicate,
                nv.time_weight
            FROM news_vectors nv
            WHERE nv.is_active = TRUE
              AND nv.is_duplicate = FALSE
        """
        params = [embedding_str]

        if ticker:
            query += " AND nv.ticker = %s"
            params.append(ticker)

        query += """
            ORDER BY nv.embedding <=> %s::vector
            LIMIT %s
        """
        params.extend([embedding_str, limit])

        cur.execute(query, params)
        return [dict(row) for row in cur.fetchall()]

    finally:
        cur.close()
        conn.close()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _vec_to_str(vec: list[float]) -> str:
    """ë²¡í„°ë¥¼ pgvector ë¬¸ìì—´ë¡œ ë³€í™˜"""
    return "[" + ",".join(str(v) for v in vec) + "]"
