"""
lib/news.py - ë‰´ìŠ¤ ìˆ˜ì§‘
ì¼ë°˜ ë‰´ìŠ¤ + ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤ (Google, Finviz, ì„¹í„°ë³„ ì‚¬ì´íŠ¸)
"""

import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from lib.base import HEADERS


def get_news(stock) -> list:
    """yfinance ë‰´ìŠ¤"""
    try:
        news = stock.news
        return news[:10] if news else []
    except:
        return []


def search_recent_news(ticker: str, days: int = 60) -> list:
    """êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ (ìµœê·¼ Nì¼ í•„í„°)"""
    try:
        cutoff_date = datetime.now() - timedelta(days=days)

        url = f"https://news.google.com/rss/search?q={ticker}+stock&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        news = []
        for item in soup.find_all("item")[:15]:
            title = item.find("title")
            link = item.find("link")
            pub_date = item.find("pubDate")

            if title:
                date_str = pub_date.text if pub_date else ""
                try:
                    parsed_date = datetime.strptime(date_str[:16], "%a, %d %b %Y")
                    if parsed_date < cutoff_date:
                        continue
                except:
                    pass

                news.append({
                    "title": title.text,
                    "link": link.text if link else "",
                    "date": date_str
                })
        return news[:10]
    except:
        return []


def get_sector_news(ticker: str, sector: str, industry: str) -> dict:
    """ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤ ìˆ˜ì§‘ (ìµœê·¼ 60ì¼)"""
    sector_news = {
        "general_news": [],
        "sector_specific": [],
        "catalysts": [],
        "source": None,
    }

    sector_lower = (sector or "").lower()
    industry_lower = (industry or "").lower()

    # 1. ì¼ë°˜ êµ¬ê¸€ ë‰´ìŠ¤ (ë°±ì—…)
    sector_news["general_news"] = search_recent_news(ticker, days=60)

    # 2. ì„¹í„°ë³„ íŠ¹í™” ë‰´ìŠ¤
    if "biotech" in industry_lower or "pharma" in industry_lower or "healthcare" in sector_lower:
        sector_news["sector_specific"] = get_biotech_news(ticker)
        sector_news["source"] = "ğŸ§¬ Biotech"
    elif "software" in industry_lower or "semiconductor" in industry_lower or "technology" in sector_lower:
        sector_news["sector_specific"] = get_tech_news(ticker)
        sector_news["source"] = "ğŸ¤– Tech/AI"
    elif "energy" in sector_lower or "oil" in industry_lower or "gas" in industry_lower:
        sector_news["sector_specific"] = get_energy_news(ticker)
        sector_news["source"] = "â›½ Energy"
    elif "auto" in industry_lower or "vehicle" in industry_lower or "ev" in industry_lower:
        sector_news["sector_specific"] = get_automotive_news(ticker)
        sector_news["source"] = "ğŸš— Automotive"
    elif "real estate" in sector_lower or "reit" in industry_lower:
        sector_news["sector_specific"] = get_realestate_news(ticker)
        sector_news["source"] = "ğŸ  Real Estate"
    elif "retail" in industry_lower or "e-commerce" in industry_lower or "store" in industry_lower:
        sector_news["sector_specific"] = get_retail_news(ticker)
        sector_news["source"] = "ğŸ›’ Retail"
    elif "food" in industry_lower or "beverage" in industry_lower or "consumer" in sector_lower:
        sector_news["sector_specific"] = get_consumer_news(ticker)
        sector_news["source"] = "ğŸ” Consumer"
    elif "bank" in industry_lower or "financial" in sector_lower or "insurance" in industry_lower:
        sector_news["sector_specific"] = get_financial_news(ticker)
        sector_news["source"] = "ğŸ¦ Financial"
    elif "industrial" in sector_lower or "aerospace" in industry_lower or "defense" in industry_lower:
        sector_news["sector_specific"] = get_industrial_news(ticker)
        sector_news["source"] = "ğŸ­ Industrial"
    else:
        sector_news["sector_specific"] = get_finviz_news(ticker)
        sector_news["source"] = "ğŸ“° General"

    return sector_news


def _google_news_search(ticker: str, keywords_suffix: str, source_label: str, limit: int = 7) -> list:
    """ê³µí†µ êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ í—¬í¼"""
    news = []
    try:
        keywords = f"{ticker} {keywords_suffix}"
        url = f"https://news.google.com/rss/search?q={keywords}&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(resp.text, "xml")

        for item in soup.find_all("item")[:limit]:
            title = item.find("title")
            if title:
                news.append({
                    "title": title.text,
                    "link": item.find("link").text if item.find("link") else "",
                    "source": source_label
                })
    except:
        pass
    return news


def get_biotech_news(ticker: str) -> list:
    """ë°”ì´ì˜¤í… ì „ìš© ë‰´ìŠ¤ (BioSpace, FiercePharma)"""
    news = []

    # 1. BioSpace ê²€ìƒ‰
    try:
        url = f"https://www.biospace.com/search?q={ticker}"
        resp = requests.get(url, headers=HEADERS, timeout=10)
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, "html.parser")
            articles = soup.select("article h3 a, .article-title a")[:5]
            for a in articles:
                news.append({
                    "title": a.text.strip(),
                    "link": a.get("href", ""),
                    "source": "BioSpace"
                })
    except:
        pass

    # 2. êµ¬ê¸€ ë‰´ìŠ¤ ë°”ì´ì˜¤í… í‚¤ì›Œë“œ
    news.extend(_google_news_search(ticker, "FDA OR clinical OR trial OR Phase OR approval", "Google/FDA", 5))

    return news


def get_tech_news(ticker: str) -> list:
    """AI/Tech ì „ìš© ë‰´ìŠ¤"""
    return _google_news_search(ticker, "AI OR artificial intelligence OR GPU OR datacenter OR cloud", "Google/AI")


def get_energy_news(ticker: str) -> list:
    """ì—ë„ˆì§€ ì „ìš© ë‰´ìŠ¤"""
    return _google_news_search(ticker, "oil OR gas OR drilling OR OPEC OR energy", "Google/Energy")


def get_automotive_news(ticker: str) -> list:
    """ìë™ì°¨/EV ì „ìš© ë‰´ìŠ¤"""
    return _google_news_search(ticker, "EV OR electric vehicle OR battery OR autonomous OR Tesla OR charging", "Google/Auto")


def get_retail_news(ticker: str) -> list:
    """ë¦¬í…Œì¼/ì´ì»¤ë¨¸ìŠ¤ ì „ìš© ë‰´ìŠ¤"""
    return _google_news_search(ticker, "retail OR e-commerce OR consumer spending OR sales OR store", "Google/Retail")


def get_consumer_news(ticker: str) -> list:
    """ì†Œë¹„ì¬/ì‹í’ˆ ì „ìš© ë‰´ìŠ¤"""
    return _google_news_search(ticker, "food OR beverage OR consumer goods OR grocery OR brand", "Google/Consumer")


def get_financial_news(ticker: str) -> list:
    """ê¸ˆìœµ/í•€í…Œí¬ ì „ìš© ë‰´ìŠ¤"""
    return _google_news_search(ticker, "bank OR fintech OR interest rate OR Fed OR lending OR credit", "Google/Finance")


def get_industrial_news(ticker: str) -> list:
    """ì‚°ì—…ì¬/ì œì¡° ì „ìš© ë‰´ìŠ¤"""
    return _google_news_search(ticker, "manufacturing OR industrial OR defense OR aerospace OR contract", "Google/Industrial")


def get_realestate_news(ticker: str) -> list:
    """ë¶€ë™ì‚°/ë¦¬ì¸  ì „ìš© ë‰´ìŠ¤"""
    return _google_news_search(ticker, "REIT OR real estate OR property OR mortgage OR housing", "Google/RealEstate")


def get_finviz_news(ticker: str) -> list:
    """Finviz ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘"""
    news = []

    try:
        url = f"https://finviz.com/quote.ashx?t={ticker}"
        resp = requests.get(url, headers=HEADERS, timeout=10)

        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, "html.parser")
            news_table = soup.find("table", {"id": "news-table"})

            if news_table:
                rows = news_table.find_all("tr")[:7]
                for row in rows:
                    link = row.find("a")
                    if link:
                        news.append({
                            "title": link.text.strip(),
                            "link": link.get("href", ""),
                            "source": "Finviz"
                        })
    except:
        pass

    return news
